\documentclass[bachelor, och, pract, times]{SCWorks}
% параметр - тип обучения - одно из значений:
%    spec     - специальность
%    bachelor - бакалавриат (по умолчанию)
%    master   - магистратура
% параметр - форма обучения - одно из значений:
%    och   - очное (по умолчанию)
%    zaoch - заочное
% параметр - тип работы - одно из значений:
%    referat    - реферат
%    coursework - курсовая работа (по умолчанию)
%    diploma    - дипломная работа
%    pract      - отчет по практике
%    nir      - отчет о научно-исследовательской работе
%    autoref    - автореферат выпускной работы
%    assignment - задание на выпускную квалификационную работу
%    review     - отзыв руководителя
%    critique   - рецензия на выпускную работу
% параметр - включение шрифта
%    times    - включение шрифта Times New Roman (если установлен)
%               по умолчанию выключен
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{graphicx}

\usepackage[sort,compress]{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}
\usepackage{minted}
\usepackage{array}
\usepackage{listings}
\usepackage[sort,compress]{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}
\usepackage{tempora}
\usepackage[hidelinks]{hyperref}

\usepackage[english,russian]{babel}

\usepackage{enumitem}

\usepackage{listings}

\lstset{
    backgroundcolor=\color{white},
    basicstyle=\footnotesize\ttfamily,
    breaklines=true,
    frame=single,
    language=Go,
    keywordstyle=\color{blue},
    commentstyle=\color{green},
    stringstyle=\color{red},
}

\usepackage[colorlinks=true]{hyperref}


\newcommand{\eqdef}{\stackrel {\rm def}{=}}
\newcommand{\No}{\textnumero}
\newtheorem{lem}{Лемма}
\setminted{style=bw,
	linenos=true,
	breaklines=true,
	numbersep=5pt,
	tabsize=2,
	fontsize=\small,
	bgcolor=white}
\setmintedinline{style=bw,
	bgcolor=white,
	fontsize=\normalsize
	}	

\begin{document}

% Кафедра (в родительном падеже)
\chair{математической кибернетики и компьютерных наук}

% Тема работы
\title{Система рекомендаций квестов и друзей на основе алгоритмов машинного обучения}

% Курс
\course{4}

% Группа
\group{451}

% Факультет (в родительном падеже) (по умолчанию "факультета КНиИТ")
%\department{факультета КНиИТ}

% Специальность/направление код - наименование
%\napravlenie{02.03.02 "--- Фундаментальная информатика и информационные технологии}
%\napravlenie{02.03.01 "--- Математическое обеспечение и администрирование информационных систем}
%\napravlenie{09.03.01 "--- Информатика и вычислительная техника}
\napravlenie{09.03.04 "--- Программная инженерия}
%\napravlenie{10.05.01 "--- Компьютерная безопасность}

% Для студентки. Для работы студента следующая команда не нужна.
%\studenttitle{Студентки}

% Фамилия, имя, отчество в родительном падеже
\author{Стеклянникова Петра Сергеевича}

% Заведующий кафедрой
\chtitle{доцент, к.\,ф.-м.\,н.} % степень, звание
\chname{С.\,В.\,Миронов}

%Научный руководитель (для реферата преподаватель проверяющий работу)
\satitle{доцент, к.\,ф.-м.\,н.} %должность, степень, звание
\saname{Сафрончик М.И.}

% Руководитель практики от организации (только для практики,
% для остальных типов работ не используется)
\patitle{доцент, к.\,ф.-м.\,н.} 
\paname{Сафрончик М.И.}

% Семестр (только для практики, для остальных
% типов работ не используется)
\term{7}

% Наименование практики (только для практики, для остальных
% типов работ не используется)
\practtype{учебная}

% Продолжительность практики (количество недель) (только для практики,
% для остальных типов работ не используется)
\duration{14}

% Даты начала и окончания практики (только для практики, для остальных
% типов работ не используется)
\practStart{01.09.2025}
\practFinish{08.12.2025}

% Год выполнения отчета
\date{2025}

\maketitle

% Включение нумерации рисунков, формул и таблиц по разделам
% (по умолчанию - нумерация сквозная)
% (допускается оба вида нумерации)
%\secNumbering


\tableofcontents

% Раздел "Обозначения и сокращения". Может отсутствовать в работе
%\abbreviations

% Раздел "Определения". Может отсутствовать в работе
%\definitions

% Раздел "Определения, обозначения и сокращения". Может отсутствовать в работе.
% Если присутствует, то заменяет собой разделы "Обозначения и сокращения" и "Определения"
%\defabbr
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\intro
Активное развитие цифровых технологий и машинного обучения создает новые возможности для создания интеллектуальных систем персонализации и рекомендаций. Современные веб-приложения, особенно в области геймификации и мотивационных систем, требуют эффективных алгоритмов для подбора контента, соответствующего индивидуальным предпочтениям пользователей.

Анализ существующих систем рекомендаций выявил необходимость применения современных подходов на основе трансформеров для работы с семантически сложными данными. Традиционные алгоритмы, такие как Collaborative Filtering и TF-IDF, показывают хорошие результаты в определенных сценариях, но имеют ограничения при работе с семантически сложными данными. Современные подходы на основе трансформеров, такие как BERT, позволяют учитывать семантическое сходство текстов, что критически важно для рекомендации контента на основе описаний. Сравнительное тестирование показало превосходство BERT по всем метрикам качества.

Дополнительной проблемой является необходимость интеграции систем рекомендаций в микросервисную архитектуру современных приложений. Разделение на независимые сервисы требует тщательного проектирования API и обеспечения эффективного взаимодействия между компонентами системы.

Современные тенденции в разработке ПО, включая микросервисную архитектуру \cite{arch1}, прогресс в области машинного обучения и развитие облачных технологий, открывают новые возможности для создания интеллектуальных систем рекомендаций. Эти технологии позволяют разрабатывать решения, способные адаптироваться к предпочтениям пользователей на качественно новом уровне.

В данном контексте актуальной задачей является разработка системы рекомендаций квестов и друзей на основе BERT для обеспечения высокой точности и релевантности рекомендаций. Проведенное сравнительное тестирование различных алгоритмов машинного обучения (BERT, TF-IDF, Collaborative Filtering KNN) показало превосходство BERT по всем метрикам качества, что подтвердило правильность выбора данного подхода. Система представляет собой интеллектуальную платформу, способную анализировать семантику контента и интересы пользователей для предложения персонализированных решений.

Практика посвящена исследованию, проектированию и разработке программного комплекса, реализующего функциональность системы рекомендаций на основе машинного обучения. В работе рассматриваются различные алгоритмы рекомендаций, сравнивается их эффективность, анализируются подходы к интеграции ML-сервисов в микросервисную архитектуру.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\textbf{Целью практики} является исследование, проектирование и разработка умного адаптивного трекера привычек и целей, представляющего собой полнофункциональное веб-приложение с архитектурой, ориентированной на обеспечение высокой производительности, масштабируемости и безопасности, и интегрирующего механизмы адаптивности, геймификации и социального взаимодействия для повышения эффективности процесса формирования привычек и достижения личных целей.

Для достижения поставленной цели в работе решается комплекс взаимосвязанных задач:

\begin{enumerate}
    \item Проведение комплексного анализа предметной области, включая изучение современных алгоритмов рекомендаций (Collaborative Filtering, Content-Based Filtering, BERT), исследование существующих систем рекомендаций и выявление их преимуществ и недостатков.
    
    \item Исследование и сравнительный анализ алгоритмов машинного обучения для рекомендаций: Collaborative Filtering на основе KNN, TF-IDF для текстового поиска, BERT для семантического анализа. Проведение сравнительного тестирования для выявления наиболее эффективного алгоритма, показавшее превосходство BERT по всем метрикам качества.
    
    \item Формирование и обоснование требований к разрабатываемой системе рекомендаций, включая функциональные требования (поиск квестов, рекомендация квестов, рекомендация друзей) и нефункциональные требования (производительность, точность рекомендаций, масштабируемость).
    
    \item Проведение сравнительного анализа технологий машинного обучения и инструментов разработки для обоснованного выбора технологического стека, включающего средства реализации ML-сервиса (Python, FastAPI, библиотеки для NLP), интеграции с основным backend и системы хранения данных.
    
    \item Проектирование архитектуры системы рекомендаций на основе микросервисного подхода с определением границ сервисов, схем взаимодействия между основным backend (Go) и Recommendation Service (Python), моделей данных и API-интерфейсов.
    
    \item Реализация алгоритма поиска квестов на основе TF-IDF для быстрого текстового поиска по описаниям квестов с учетом категорий и метаданных.
    
    \item Реализация алгоритма семантического поиска на основе BERT для поиска квестов с учетом семантического сходства текстовых описаний, преодолевающего ограничения ключевых слов.
    
    \item Реализация алгоритма рекомендации квестов на основе Collaborative Filtering (KNN) для подбора квестов на основе истории взаимодействия пользователей с системой и схожести их предпочтений.
    
    \item Реализация гибридного подхода к рекомендации квестов, сочетающего Collaborative Filtering и семантический анализ на основе BERT для повышения точности и релевантности рекомендаций.
    
    \item Реализация алгоритма рекомендации друзей на основе Collaborative Filtering, анализирующего схожесть интересов пользователей на основе выполненных квестов и предпочтений по категориям.
    
    \item Разработка Recommendation Service на Python с использованием FastAPI, обеспечивающего RESTful API для взаимодействия с основным backend и эффективную обработку запросов на рекомендации.
    
    \item Интеграция Recommendation Service с основным backend-приложением (Go), включая реализацию клиентских компонентов для взаимодействия с ML-сервисом, обработку ошибок и таймаутов.
    
    \item Проведение сравнительного анализа эффективности различных алгоритмов (BERT vs TF-IDF vs Collaborative Filtering) на реальных данных, оценка метрик качества рекомендаций (precision, recall, F1-score). Результаты показали превосходство BERT по всем метрикам, что привело к выбору BERT как единственного алгоритма для продакшена.
    
    \item Обеспечение производительности и масштабируемости Recommendation Service через оптимизацию алгоритмов, кэширование результатов и эффективную работу с данными.
    
    \item Документирование процесса проектирования, разработки и развертывания системы рекомендаций, включая описание алгоритмов, архитектурных решений, API-документацию и результаты сравнительного анализа.
\end{enumerate}

Решение указанных задач позволит создать полнофункциональный, технологически современный и практически значимый программный продукт, демонстрирующий комплексный подход к решению проблемы персонализации контента и рекомендаций на основе машинного обучения, а также подтверждающий высокий уровень профессиональной подготовки автора работы в области программной инженерии и машинного обучения.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Анализ предметной области и существующих решений}

\subsection{Актуальность темы разработки систем рекомендаций на основе машинного обучения}

Разработка интеллектуальных систем рекомендаций представляет собой высокоактуальное направление на стыке программной инженерии, машинного обучения и обработки естественного языка. Актуальность темы обусловлена несколькими взаимосвязанными факторами, имеющими существенное значение как для развития технологий, так и для решения практических задач современного общества.

Во-первых, наблюдается устойчивый рост интереса к персонализации пользовательского опыта в различных областях: от электронной коммерции до образовательных и развлекательных платформ. Согласно исследованиям, системы рекомендаций способны увеличить конверсию на 20-30\% и повысить вовлеченность пользователей на 40-60\%. Рост этого направления стимулируется накоплением больших объемов данных о поведении пользователей, развитием алгоритмов машинного обучения и доступностью вычислительных ресурсов для обработки сложных моделей.

Во-вторых, современные подходы к рекомендациям требуют применения алгоритмов, способных понимать семантику контента. Традиционные алгоритмы, такие как Collaborative Filtering и TF-IDF, показывают хорошие результаты в определенных сценариях, но имеют ограничения при работе с семантически сложными данными. Современные трансформеры, такие как BERT, позволяют учитывать семантическое сходство текстов, что критически важно для рекомендации контента на основе описаний. Сравнительное тестирование подтвердило превосходство BERT по всем метрикам качества.

С технологической точки зрения актуальность темы подчеркивается созреванием необходимых технологических предпосылок: широкое распространение облачных вычислений, развитие микросервисных архитектур \cite{arch1}, прогресс в области обработки естественного языка и доступность предобученных моделей создают уникальную возможность для построения действительно интеллектуальных систем рекомендаций.


\subsection{Анализ современной литературы и существующих решений}
\subsubsection{Алгоритмы Collaborative Filtering}

Collaborative Filtering является одним из наиболее распространенных подходов к построению систем рекомендаций. Основная идея метода заключается в использовании поведения и предпочтений других пользователей для предсказания интересов целевого пользователя. В работе Sarwar et al. (2001) «Item-based collaborative filtering recommendation algorithms» подробно рассматриваются различные варианты Collaborative Filtering, включая user-based и item-based подходы.

K-ближайших соседей (KNN) является классическим алгоритмом Collaborative Filtering, который находит пользователей или элементы, наиболее похожие на целевой объект, на основе метрик сходства (косинусное сходство, корреляция Пирсона). Преимуществами KNN являются простота реализации и интерпретируемость результатов. Однако метод страдает от проблемы разреженности данных (sparsity problem) и холодного старта (cold start problem) для новых пользователей или элементов.

В работе Ricci et al. (2011) «Recommender Systems Handbook» систематизированы различные подходы к Collaborative Filtering, включая матричную факторизацию и глубокое обучение. Современные исследования показывают, что гибридные подходы, сочетающие Collaborative Filtering с другими методами, демонстрируют лучшие результаты.

\subsubsection{Методы текстового поиска: TF-IDF}

Term Frequency-Inverse Document Frequency (TF-IDF) является классическим методом для оценки важности терминов в документах относительно коллекции документов. Формула TF-IDF определяется как:

$$TF\text{-}IDF(t,d) = TF(t,d) \times IDF(t)$$

где $TF(t,d)$ — частота термина $t$ в документе $d$, а $IDF(t) = \log\frac{N}{df(t)}$ — обратная частота документа, где $N$ — общее количество документов, а $df(t)$ — количество документов, содержащих термин $t$.

TF-IDF широко используется для текстового поиска и ранжирования документов. В контексте систем рекомендаций TF-IDF позволяет находить элементы с похожим текстовым содержанием, что особенно полезно для рекомендации контента на основе описаний. Однако метод имеет ограничения: он не учитывает семантическое сходство и синонимию, работает только с точными совпадениями терминов.

\subsubsection{Семантический анализ на основе BERT}

Bidirectional Encoder Representations from Transformers (BERT) представляет собой модель трансформера, предобученную на больших корпусах текстов. BERT способен понимать контекст слов в обоих направлениях (bidirectional), что позволяет ему лучше улавливать семантические связи по сравнению с традиционными методами.

В работе Devlin et al. (2018) «BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding» показано, что BERT достигает state-of-the-art результатов в различных задачах обработки естественного языка. Для задач семантического поиска BERT позволяет находить документы, семантически похожие на запрос, даже при отсутствии точных совпадений терминов.

Применение BERT для рекомендаций требует вычисления эмбеддингов текстовых описаний и использования метрик сходства (например, косинусное сходство) для поиска похожих элементов. Преимуществами BERT являются способность понимать семантику и контекст, что преодолевает ограничения TF-IDF. Однако метод требует значительных вычислительных ресурсов и времени на инференс.

\subsubsection{Гибридные подходы к рекомендациям}

Современные исследования показывают, что комбинация различных методов машинного обучения часто превосходит отдельные алгоритмы. В работе Burke (2002) «Hybrid Recommender Systems: Survey and Experiments» систематизированы различные стратегии комбинирования алгоритмов: взвешенное объединение, переключение между методами, каскадирование и др.

Гибридный подход, сочетающий Collaborative Filtering и семантический анализ на основе BERT, позволяет преодолеть ограничения каждого метода в отдельности: Collaborative Filtering учитывает поведенческие паттерны пользователей, а BERT обеспечивает понимание семантики контента. Такое сочетание особенно эффективно для систем с разнообразным текстовым контентом.

\subsubsection{Технологические аспекты разработки ML-сервисов}

Современная литература по программной инженерии предлагает различные архитектурные подходы к построению систем машинного обучения. Работа Ричардсона (Richardson, 2018) «Microservices Patterns» обосновывает преимущества микросервисной архитектуры для систем, требующих высокой масштабируемости и возможности независимого развертывания компонентов. Для ML-сервисов, которые могут требовать различных вычислительных ресурсов и частых обновлений моделей, такой подход представляется особенно подходящим.

FastAPI, современный веб-фреймворк для Python, обеспечивает высокую производительность и простоту разработки RESTful API для ML-сервисов. В работе Ramírez (2021) «FastAPI Modern Python Web Development» рассматриваются практики разработки ML-сервисов с использованием FastAPI, включая асинхронную обработку запросов, валидацию данных и документацию API.

Вопросы производительности и масштабируемости ML-сервисов подробно освещены в работе Huyen (2022) «Designing Machine Learning Systems», где рассматриваются методы оптимизации инференса, кэширования результатов и батчинга запросов для повышения пропускной способности системы.

\subsubsection{Анализ существующих систем рекомендаций}

Проведенный анализ существующих систем рекомендаций позволяет выделить несколько категорий решений:

\textbf{Amazon Recommendation System} — одна из наиболее известных коммерческих систем рекомендаций, использующая гибридный подход, сочетающий Collaborative Filtering, Content-Based Filtering и глубокое обучение. Система демонстрирует высокую эффективность, увеличивая продажи на 20-30\%. Однако архитектура системы является проприетарной и детали реализации не раскрываются.

\textbf{Netflix Recommendation Algorithm} — использует сложную комбинацию алгоритмов, включая матричную факторизацию, ограниченные машины Больцмана и глубокие нейронные сети. Система учитывает не только явные предпочтения (рейтинги), но и неявные сигналы (время просмотра, паузы, перемотки). Основным ограничением является высокая вычислительная сложность и требования к инфраструктуре.

\textbf{Spotify Discover Weekly} — использует Collaborative Filtering на основе анализа музыкальных предпочтений пользователей и аудиофильтрацию для анализа акустических свойств треков. Система успешно сочетает поведенческие и контентные сигналы. Однако методология не полностью раскрыта, что затрудняет воспроизведение результатов.

\textbf{YouTube Recommendation System} — использует глубокое обучение для ранжирования видео на основе истории просмотров, поисковых запросов и метаданных контента. Система демонстрирует высокую персонализацию, но также имеет проблемы с фильтральными пузырями и рекомендацией экстремального контента.

Проведенный анализ выявил, что современные системы рекомендаций все чаще используют алгоритмы на основе трансформеров, такие как BERT, для понимания семантики контента. Однако открытые реализации, демонстрирующие сравнительный анализ эффективности различных методов (BERT, TF-IDF, Collaborative Filtering) в единой системе, встречаются редко. Именно эту нишу призвана заполнить разрабатываемая в рамках данной работы система, предоставляющая открытую реализацию BERT-основанных рекомендаций и сравнительный анализ различных алгоритмов, показавший превосходство BERT по всем метрикам качества.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Технологические аспекты разработки систем рекомендаций}
\subsubsection{Архитектурные подходы и микросервисная архитектура}

В контексте разработки систем рекомендаций особое значение приобретает выбор архитектурного подхода, обеспечивающего разделение основного backend и ML-сервиса. Микросервисная архитектура позволяет независимо разрабатывать, развертывать и масштабировать компоненты системы, что критически важно для ML-сервисов, требующих различных вычислительных ресурсов и частых обновлений моделей.

Основной backend реализован на Go с использованием фреймворка Gin \cite{go_api_handbook}, что обеспечивает высокую производительность обработки запросов (до 50,000 запросов в секунду) и эффективное использование ресурсов. Язык Go \cite{go_documentation} обеспечивает конкурентность через goroutines, что особенно важно для систем, обрабатывающих множество одновременных запросов к Recommendation Service \cite{go2}.

Recommendation Service реализован на Python с использованием FastAPI, что обеспечивает:
\begin{itemize}
    \item Высокую производительность благодаря асинхронной обработке запросов
    \item Простоту интеграции с библиотеками машинного обучения (scikit-learn, transformers, sentence-transformers)
    \item Автоматическую генерацию документации API (OpenAPI/Swagger)
    \item Валидацию данных через Pydantic
\end{itemize}

Выбор Python для ML-сервиса обусловлен богатой экосистемой библиотек для машинного обучения и обработки естественного языка, включая предобученные модели BERT через библиотеку transformers. Go был бы менее подходящим из-за ограниченной поддержки ML-библиотек, а Node.js не подходит для вычислительно интенсивных задач машинного обучения.

\subsubsection{Библиотеки машинного обучения и обработки естественного языка}

Для реализации алгоритмов рекомендаций используются следующие библиотеки Python:

\textbf{sentence-transformers} — библиотека для работы с предобученными моделями трансформеров, включая BERT. Позволяет легко получать семантические эмбеддинги текстов для вычисления сходства между описаниями квестов. Используется модель \texttt{all-MiniLM-L6-v2}, оптимизированная для задач семантического поиска.

\textbf{scikit-learn} — библиотека для машинного обучения, используемая для реализации Collaborative Filtering на основе KNN. Предоставляет эффективные реализации алгоритмов ближайших соседей с различными метриками расстояния (косинусное сходство, евклидово расстояние).

\textbf{TfidfVectorizer} из scikit-learn — используется для реализации TF-IDF поиска. Обеспечивает векторизацию текстов с учетом частоты терминов и обратной частоты документов, что позволяет эффективно находить релевантные квесты по текстовым запросам.

\textbf{numpy и scipy} — используются для эффективных вычислений с матрицами и векторами, необходимых для вычисления метрик сходства и обработки эмбеддингов.

\subsubsection{Взаимодействие между микросервисами}

Взаимодействие между основным backend (Go) и Recommendation Service (Python) осуществляется через RESTful API. Основной backend отправляет HTTP POST запросы к Recommendation Service с таймаутом 30 секунд для предотвращения зависаний при обработке запросов.

Структура взаимодействия:
\begin{itemize}
    \item \texttt{POST /api/search} — поиск квестов по текстовому запросу (BERT)
    \item \texttt{POST /api/quests/recommend} — рекомендация квестов на основе истории пользователя (BERT)
    \item \texttt{POST /api/users/recommend} — рекомендация друзей на основе семантического сходства интересов (BERT)
    \item \texttt{POST /api/quests/add} — добавление новых квестов в индекс для поиска
    \item \texttt{POST /api/users/add} — добавление данных пользователей для Collaborative Filtering
\end{itemize}

Все запросы используют JSON для сериализации данных. Recommendation Service возвращает результаты с оценками сходства (similarity scores) и объяснениями рекомендаций, что позволяет пользователям понимать, почему им рекомендован тот или иной контент.

\subsubsection{Кэширование и оптимизация производительности}

Для обеспечения высокой производительности Recommendation Service используются следующие техники оптимизации:

\begin{itemize}
    \item \textbf{Кэширование эмбеддингов} — предвычисленные BERT-эмбеддинги квестов сохраняются в памяти для быстрого доступа при поиске и рекомендациях
    \item \textbf{Батчинг запросов} — группировка нескольких запросов для обработки в одном батче, что повышает эффективность использования GPU/CPU
    \item \textbf{Ленивая загрузка моделей} — модели BERT загружаются только при первом запросе, что ускоряет старт сервиса
    \item \textbf{Индексация для KNN} — использование эффективных структур данных (например, Ball Tree или KD-Tree) для быстрого поиска ближайших соседей в Collaborative Filtering
\end{itemize}

Для работы с большими объемами данных рекомендуется использование векторных баз данных (например, FAISS от Facebook или Milvus) для эффективного поиска похожих эмбеддингов, однако в текущей реализации используется in-memory поиск, достаточный для средних объемов данных.

\subsubsection{API design и REST principles}

RESTful API проектируется в соответствии с принципами \cite{api1}:
\begin{itemize}
    \item Stateless взаимодействие
    \item Единообразие интерфейса
    \item Кэшируемость ответов
    \item Слоистая архитектура
\end{itemize}

Пример структуры endpoint'ов:
\begin{verbatim}
POST   /api/auth/register    - регистрация
POST   /api/auth/login       - аутентификация
GET    /api/quests           - получение квестов
POST   /api/quests/{id}/start - старт квеста
PATCH  /api/tasks/{id}/complete - выполнение задачи
GET    /api/friends          - список друзей
POST   /api/friends/{id}/invite - приглашение в друзья
\end{verbatim}

\subsubsection{Микросервисная архитектура и контейнеризация}

Для обеспечения масштабируемости система проектируется с учетом возможного перехода на микросервисную архитектуру. Docker контейнеризация обеспечивает \cite{docker1, docker2}:
\begin{itemize}
    \item Изоляцию зависимостей
    \item Воспроизводимость окружения
    \item Простое развертывание
\end{itemize}

Оркестрация контейнеров через Docker Compose или Kubernetes позволяет управлять многоконтейнерными приложениями и обеспечивать:
\begin{itemize}
    \item Service discovery
    \item Load balancing
    \item Auto-scaling
    \item Self-healing
\end{itemize}

\subsubsection{Мониторинг и логирование}

Для обеспечения наблюдаемости (observability) системы применяются:
\begin{itemize}
    \item Structured logging в формате JSON
    \item Metrics collection через Prometheus
    \item Health checks и readiness probes
\end{itemize}

\subsubsection{Тестирование и качество кода}

Современные практики тестирования включают:
\begin{itemize}
    \item Unit тесты с покрытием критической бизнес-логики
    \item Интеграционные тесты для проверки взаимодействия с БД
    \item E2E тесты для проверки пользовательских сценариев
    \item Нагрузочное тестирование для оценки производительности
\end{itemize}

Инструменты обеспечения качества:
\begin{itemize}
    \item ESLint и Prettier для фронтенда
    \item golangci-lint для бекенда
    \item SonarQube для анализа качества кода
    \item Git hooks для pre-commit проверок
\end{itemize}

Эти технологические аспекты формируют прочный фундамент для создания надежной, масштабируемой и эффективной системы рекомендаций, способной обрабатывать большие объемы данных и обеспечивать высокую точность рекомендаций.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Проектирование и реализация системы}

\subsection{Архитектура системы}

Разрабатываемая система построена на микросервисной архитектуре с использованием технологического стека Go + Gin + PostgreSQL для основного backend, Python + FastAPI для Recommendation Service и React.js для frontend. Архитектура обеспечивает разделение ответственности между сервисами и возможность независимого масштабирования компонентов \cite{arch1}.
Общая архитектура системы представлена на рис. \ref{fig:architecture}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.1\textwidth]{diagrams/arch_diagram.png}
    \caption{Общая архитектура системы}
    \label{fig:architecture}
\end{figure}

Система организована в четыре основных слоя:
\begin{itemize}
    \item \textbf{Frontend Layer} - React.js приложение, отвечающее за пользовательский интерфейс
    \item \textbf{Backend Layer} - Go сервер с фреймворком Gin, реализующий бизнес-логику и REST API
    \item \textbf{ML Service Layer} - Python сервис на FastAPI, реализующий алгоритмы рекомендаций и поиска на основе BERT (TF-IDF и Collaborative Filtering были протестированы для сравнения, но не используются в продакшене)
    \item \textbf{Data Layer} - PostgreSQL база данных для хранения всей информации системы
\end{itemize}

Взаимодействие между Backend Layer и ML Service Layer осуществляется через HTTP REST API с таймаутами для обеспечения отказоустойчивости системы.  

\subsubsection{Технологический стек и обоснование выбора}

\textbf{Backend} реализован на Go с использованием фреймворка Gin \cite{go_backend}. Выбор Go обусловлен его отличной поддержкой конкурентности, что критически важно для системы, обрабатывающей множество одновременных запросов к Recommendation Service \cite{go_practice}.

\textbf{Recommendation Service} реализован на Python с использованием FastAPI. Выбор Python обусловлен богатой экосистемой библиотек для машинного обучения (sentence-transformers для BERT) и простотой интеграции предобученных моделей. В процессе разработки также использовались scikit-learn для реализации TF-IDF и Collaborative Filtering для сравнительного тестирования, но в продакшене используется только BERT.

\textbf{База данных} — PostgreSQL выбрана как надежная реляционная СУБД с богатым функционалом, поддерживающая сложные запросы и транзакции \cite{db1}. Используется для хранения метаданных квестов, истории взаимодействия пользователей и данных для построения семантических профилей.

\textbf{Frontend} разработан на React.js с использованием функциональных компонентов и хуков \cite{js4}. Выбор React обусловлен его богатой экосистемой, компонентным подходом и простотой разработки пользовательских интерфейсов \cite{js2}.

\subsection{Реализация алгоритмов рекомендаций и поиска}

В рамках разработки системы были протестированы различные алгоритмы машинного обучения для поиска и рекомендаций: TF-IDF, Collaborative Filtering (KNN) и BERT. Сравнительный анализ на реальных данных показал превосходство BERT по всем метрикам качества (precision, recall, F1-score) и способности понимать семантику текстов. В результате для продакшена выбран BERT как единственный алгоритм для поиска квестов и рекомендаций (как квестов, так и друзей).

\subsubsection{Сравнительное тестирование: TF-IDF vs BERT}

В процессе разработки был реализован и протестирован алгоритм TF-IDF для сравнения с BERT. TF-IDF (Term Frequency-Inverse Document Frequency) работает следующим образом:

\begin{enumerate}
    \item \textbf{Векторизация квестов}: Каждый квест представляется в виде вектора TF-IDF на основе его названия, описания и категории. Используется \texttt{TfidfVectorizer} из scikit-learn с параметрами:
    \begin{itemize}
        \item Максимальное количество признаков: 1000
        \item Минимальная частота документа (min\_df): 1
        \item Максимальная частота документа (max\_df): 0.95
        \item N-граммы: униграммы и биграммы для учета фраз
    \end{itemize}
    
    \item \textbf{Векторизация запроса}: Пользовательский запрос преобразуется в вектор TF-IDF с использованием той же модели векторизации.
    
    \item \textbf{Вычисление сходства}: Косинусное сходство между вектором запроса и векторами всех квестов вычисляется по формуле:
    $$\text{similarity}(q, d) = \frac{\mathbf{q} \cdot \mathbf{d}}{||\mathbf{q}|| \times ||\mathbf{d}||}$$
    где $\mathbf{q}$ — вектор запроса, $\mathbf{d}$ — вектор документа (квеста).
    
    \item \textbf{Ранжирование и фильтрация}: Квесты ранжируются по убыванию сходства, применяется фильтрация по категориям и статусу (если указано), возвращаются top-K наиболее релевантных результатов.
\end{enumerate}

Преимущества TF-IDF: быстрая обработка запросов (O(n) где n — количество квестов), низкие требования к вычислительным ресурсам, хорошая интерпретируемость результатов.

Ограничения: не учитывает семантическое сходство (синонимы, контекст), работает только с точными совпадениями терминов, требует предобработки текста (токенизация, стемминг).

\textbf{Результаты тестирования}: TF-IDF показал Precision@10: 0.65, Recall@10: 0.58, F1-score@10: 0.61, среднее время обработки: 15 мс. Однако BERT продемонстрировал значительно более высокие результаты (Precision@10: 0.78, Recall@10: 0.72, F1-score@10: 0.75), что подтвердило его превосходство в понимании семантики и контекста. В связи с этим для продакшена выбран BERT.

\subsubsection{Алгоритм семантического поиска на основе BERT (основной метод)}

BERT (Bidirectional Encoder Representations from Transformers) используется для семантического поиска квестов, преодолевающего ограничения ключевых слов. Алгоритм реализован следующим образом:

\begin{enumerate}
    \item \textbf{Предобработка текстов}: Названия и описания квестов объединяются в единый текст, который нормализуется (удаление лишних пробелов, приведение к нижнему регистру).
    
    \item \textbf{Генерация эмбеддингов}: Используется предобученная модель \texttt{all-MiniLM-L6-v2} из библиотеки sentence-transformers. Модель генерирует 384-мерные эмбеддинги для каждого квеста:
    $$\mathbf{e}_d = \text{BERT}(\text{concat}(\text{title}_d, \text{description}_d))$$
    где $\mathbf{e}_d$ — эмбеддинг квеста $d$.
    
    \item \textbf{Кэширование эмбеддингов}: Эмбеддинги всех квестов предвычисляются при загрузке сервиса и сохраняются в памяти для быстрого доступа, что позволяет избежать повторных вычислений при каждом запросе.
    
    \item \textbf{Семантический поиск}: При получении поискового запроса генерируется эмбеддинг запроса $\mathbf{e}_q$, затем вычисляется косинусное сходство со всеми эмбеддингами квестов:
    $$\text{similarity}(q, d) = \cos(\mathbf{e}_q, \mathbf{e}_d) = \frac{\mathbf{e}_q \cdot \mathbf{e}_d}{||\mathbf{e}_q|| \times ||\mathbf{e}_d||}$$
    
    \item \textbf{Ранжирование}: Квесты ранжируются по убыванию семантического сходства, возвращаются top-K наиболее релевантных результатов.
\end{enumerate}

Преимущества BERT: понимание семантики и контекста, способность находить релевантные результаты даже при отсутствии точных совпадений терминов, учет синонимов и связанных понятий, превосходство по всем метрикам качества по сравнению с TF-IDF.

Ограничения: более высокие требования к вычислительным ресурсам, большее время обработки запросов по сравнению с TF-IDF (120 мс против 15 мс), необходимость предобученных моделей. Однако значительное повышение точности (на 23\% по F1-score) компенсирует увеличение времени обработки.

\textbf{Результаты тестирования}: BERT показал Precision@10: 0.78, Recall@10: 0.72, F1-score@10: 0.75, что на 20\% выше результатов TF-IDF. На основе этих результатов BERT выбран как основной и единственный алгоритм для поиска квестов в продакшене.

\subsubsection{Сравнительное тестирование: Collaborative Filtering (KNN) vs BERT}

В процессе разработки был реализован и протестирован алгоритм Collaborative Filtering на основе KNN для сравнения с BERT. Collaborative Filtering работает следующим образом:

\begin{enumerate}
    \item \textbf{Построение матрицы взаимодействий}: Создается матрица $M_{n \times m}$, где $n$ — количество пользователей, $m$ — количество квестов. Элемент $M_{i,j}$ представляет взаимодействие пользователя $i$ с квестом $j$:
    $$M_{i,j} = \begin{cases}
        1 & \text{если пользователь } i \text{ выполнил квест } j \\
        0.5 & \text{если пользователь } i \text{ начал квест } j \\
        0 & \text{иначе}
    \end{cases}$$
    
    \item \textbf{Вычисление сходства пользователей}: Для целевого пользователя $u$ вычисляется сходство со всеми другими пользователями с использованием косинусного сходства:
    $$\text{similarity}(u, v) = \frac{\mathbf{M}_u \cdot \mathbf{M}_v}{||\mathbf{M}_u|| \times ||\mathbf{M}_v||}$$
    где $\mathbf{M}_u$ и $\mathbf{M}_v$ — векторы взаимодействий пользователей $u$ и $v$.
    
    \item \textbf{Поиск K ближайших соседей}: Используется алгоритм KNN из scikit-learn (\texttt{NearestNeighbors}) с метрикой косинусного сходства для нахождения K наиболее похожих пользователей (по умолчанию K=10).
    
    \item \textbf{Генерация рекомендаций}: Для каждого квеста, который не был выполнен целевым пользователем, вычисляется взвешенная сумма взаимодействий похожих пользователей:
    $$\text{score}(u, q) = \frac{\sum_{v \in N(u)} \text{similarity}(u, v) \times M_{v,q}}{\sum_{v \in N(u)} |\text{similarity}(u, v)|}$$
    где $N(u)$ — множество K ближайших соседей пользователя $u$.
    
    \item \textbf{Ранжирование и фильтрация}: Квесты ранжируются по убыванию score, применяется фильтрация по категориям (если указано), возвращаются top-K наиболее релевантных рекомендаций.
\end{enumerate}

Преимущества Collaborative Filtering: учет поведенческих паттернов пользователей, способность находить неочевидные связи между квестами, не требует анализа содержания квестов.

Ограничения: проблема холодного старта для новых пользователей или квестов, проблема разреженности данных при малом количестве взаимодействий, вычислительная сложность O(n²) для больших пользовательских баз.

\textbf{Результаты тестирования}: Collaborative Filtering показал Precision@10: 0.68, Recall@10: 0.64, F1-score@10: 0.66. Однако BERT для рекомендаций квестов продемонстрировал значительно более высокие результаты, превосходя CF по всем метрикам. В связи с этим для продакшена выбран BERT как единственный алгоритм для рекомендаций.

\subsubsection{Использование BERT для рекомендаций квестов и друзей}

На основе результатов сравнительного тестирования для рекомендаций квестов и друзей используется семантический анализ на основе BERT. Алгоритм работает следующим образом:

\begin{enumerate}
    \item \textbf{Построение профиля пользователя}: На основе выполненных квестов пользователя формируется семантический профиль через BERT-эмбеддинги выполненных квестов. Профиль представляет собой усредненный эмбеддинг всех выполненных квестов:
    $$\mathbf{p}_u = \frac{1}{|U|} \sum_{q \in U} \mathbf{e}_q$$
    где $U$ — множество выполненных квестов пользователя $u$, $\mathbf{e}_q$ — BERT-эмбеддинг квеста $q$.
    
    \item \textbf{Семантическое ранжирование квестов}: Для каждого потенциально рекомендованного квеста вычисляется семантическое сходство с профилем пользователя:
    $$\text{score}(u, q) = \cos(\mathbf{p}_u, \mathbf{e}_q)$$
    где $\mathbf{e}_q$ — BERT-эмбеддинг квеста $q$.
    
    \item \textbf{Фильтрация и ранжирование}: Квесты фильтруются по категориям (если указано) и ранжируются по убыванию score, возвращаются top-K рекомендаций с объяснениями на основе семантического сходства.
\end{enumerate}

Преимущества использования BERT для рекомендаций: глубокое понимание семантики контента, способность находить релевантные квесты даже при отсутствии точных совпадений, учет контекста и связанных понятий, превосходство по всем метрикам качества по сравнению с Collaborative Filtering.

\subsubsection{Алгоритм рекомендации друзей на основе BERT}

Рекомендация друзей основана на семантическом анализе интересов пользователей с использованием BERT:

\begin{enumerate}
    \item \textbf{Построение семантического профиля интересов}: Для каждого пользователя создается семантический профиль на основе BERT-эмбеддингов выполненных квестов. Профиль представляет собой усредненный эмбеддинг всех выполненных квестов:
    $$\mathbf{p}_u = \frac{1}{|U|} \sum_{q \in U} \mathbf{e}_q$$
    где $U$ — множество выполненных квестов пользователя $u$.
    
    \item \textbf{Вычисление семантического сходства интересов}: Для целевого пользователя вычисляется косинусное сходство его семантического профиля со всеми другими пользователями:
    $$\text{similarity}(u, v) = \cos(\mathbf{p}_u, \mathbf{p}_v)$$
    где $\mathbf{p}_u$ и $\mathbf{p}_v$ — семантические профили пользователей.
    
    \item \textbf{Ранжирование пользователей}: Пользователи ранжируются по убыванию семантического сходства.
    
    \item \textbf{Фильтрация существующих друзей}: Из списка рекомендаций исключаются пользователи, с которыми уже установлена дружба.
    
    \item \textbf{Генерация объяснений}: Для каждой рекомендации генерируется объяснение на основе семантического сходства интересов и общих категорий выполненных квестов.
\end{enumerate}

Преимущества использования BERT для рекомендации друзей: глубокое понимание семантики интересов пользователей, способность находить друзей с похожими интересами даже при отсутствии точных совпадений в категориях, учет контекста и связанных понятий в выполненных квестах.

\subsection{Реализация основного backend-приложения}

Основной backend-сервис реализован на Go с использованием фреймворка Gin и обеспечивает всю бизнес-логику приложения, взаимодействие с базой данных PostgreSQL и интеграцию с внешними сервисами (LLM API и Recommendation Service).

\subsubsection{Система аутентификации и авторизации}

Реализована полнофункциональная система аутентификации на основе JWT (JSON Web Tokens). Процесс аутентификации включает следующие этапы:

\begin{enumerate}
    \item \textbf{Регистрация пользователя}: При регистрации пароль хешируется с использованием алгоритма bcrypt с work factor 10, что обеспечивает защиту от brute-force атак. Хеш пароля сохраняется в таблице \texttt{users} вместе с уникальными \texttt{username} и \texttt{email}.
    
    \item \textbf{Аутентификация}: При успешной аутентификации генерируется JWT токен с временем жизни 24 часа. Токен содержит идентификатор пользователя (\texttt{user\_id}) в payload и подписывается секретным ключом, хранящимся в переменных окружения.
    
    \item \textbf{Авторизация}: Middleware \texttt{JWTAuthMiddleware} проверяет наличие и валидность токена в заголовке \texttt{Authorization} каждого защищенного запроса. При успешной проверке идентификатор пользователя сохраняется в контексте запроса для дальнейшего использования в обработчиках.
\end{enumerate}

Кодовая реализация системы аутентификации представлена в приложении \ref{app:jwt_auth}.

\subsubsection{Система уровней и геймификация}

Реализована система прогрессии игрока на основе накопленного опыта (XP) с использованием квадратичной формулы расчета уровня:

$$level = \lfloor \sqrt{\frac{XP}{100}} \rfloor + 1$$

Данная формула обеспечивает экспоненциальный рост требований к опыту для каждого следующего уровня, что создает сбалансированную прогрессию:
\begin{itemize}
    \item Уровень 1: 0-99 XP
    \item Уровень 2: 100-399 XP
    \item Уровень 3: 400-899 XP
    \item Уровень 4: 900-1599 XP
    \item И так далее
\end{itemize}

При выполнении задачи или завершении квеста опыт начисляется пользователю, и уровень автоматически пересчитывается с использованием функции \texttt{calculateLevel}. Обновление уровня происходит атомарно в рамках транзакции вместе с начислением опыта и монет, что гарантирует целостность данных.

\subsubsection{Система фильтрации квестов по уровню сложности}

Квесты фильтруются на основе уровня пользователя для обеспечения постепенного открытия контента. Алгоритм фильтрации реализован в методе \texttt{GetAvailableQuests}:

\begin{enumerate}
    \item Получение текущего уровня пользователя и баланса монет из базы данных.
    
    \item Фильтрация квестов по следующим критериям:
    \begin{itemize}
        \item \texttt{difficulty <= user.level + 1} — пользователь может видеть квесты со сложностью не более чем на 1 уровень выше его текущего уровня
        \item \texttt{price <= user.coin\_balance} — пользователь может видеть только те квесты, которые он может себе позволить
        \item Квест не должен быть уже куплен или пройден пользователем
    \end{itemize}
    
    \item Возврат отфильтрованного списка доступных квестов.
\end{enumerate}

Такая система обеспечивает постепенное открытие нового контента по мере прогрессии пользователя, создавая мотивацию для выполнения квестов и повышения уровня.

\subsubsection{Управление квестами и задачами с использованием транзакций}

Все критические операции с квестами и задачами выполняются в рамках транзакций PostgreSQL для обеспечения атомарности и целостности данных. Используется метод \texttt{BeginTxx} для создания транзакций с контекстом, что позволяет корректно обрабатывать таймауты и отмену операций.

\textbf{Процесс покупки квеста} реализован следующим образом:
\begin{enumerate}
    \item Начало транзакции: \texttt{tx, err := r.db.BeginTxx(ctx, nil)}
    \item Проверка существования квеста и достаточности средств пользователя
    \item Создание записи в \texttt{user\_quests} со статусом \texttt{'purchased'}
    \item Создание записей в \texttt{user\_tasks} для всех задач квеста со статусом \texttt{'not\_started'}
    \item Списывание монет с баланса пользователя: \texttt{UPDATE users SET coin\_balance = coin\_balance - price}
    \item Создание записи транзакции в \texttt{user\_coin\_transactions} для аудита финансовых операций
    \item Подтверждение транзакции: \texttt{tx.Commit()} или откат при ошибке: \texttt{tx.Rollback()}
\end{enumerate}

\textbf{Процесс выполнения задачи} также выполняется в транзакции:
\begin{enumerate}
    \item Проверка существования квеста в статусе \texttt{'started'} или \texttt{'purchased'}
    \item Проверка существования задачи в статусе \texttt{'active'} или \texttt{'not\_started'}
    \item Если квест в статусе \texttt{'purchased'}, автоматический старт квеста и активация всех задач
    \item Получение базовых наград задачи (\texttt{base\_xp\_reward}, \texttt{base\_coin\_reward})
    \item Начисление наград пользователю с автоматическим пересчетом уровня через функцию \texttt{addXPAndCoinsWithLevelUp}
    \item Обновление статуса задачи на \texttt{'completed'} с сохранением начисленных наград
    \item Подтверждение транзакции
\end{enumerate}

Использование транзакций гарантирует, что все связанные операции выполняются атомарно: либо все изменения применяются, либо ни одно из них не применяется, что критически важно для финансовых операций и системы прогрессии.

\subsubsection{AI-генерация квестов через LLM API}

Реализована интеграция с LLM API (Intelligence.IO Solutions) для генерации персонализированных квестов на основе текстового запроса пользователя. Используется модель \texttt{moonshotai/Kimi-K2-Thinking}, которая обладает встроенной системой цензуры для предотвращения генерации вредного контента.

\textbf{Процесс генерации квеста:}
\begin{enumerate}
    \item \textbf{Получение запроса}: Пользователь отправляет текстовый промпт с описанием желаемого квеста через endpoint \texttt{POST /quests/generate}.
    
    \item \textbf{Формирование системного промпта}: Создается детальный системный промпт, определяющий структуру JSON-ответа, включающую метаданные квеста (название, описание, категория, редкость, сложность, цена, награды) и массив задач с их параметрами.
    
    \item \textbf{Отправка запроса к LLM}: Выполняется HTTP POST запрос к API \texttt{https://api.intelligence.io.solutions/api/v1/chat/completions} с использованием Bearer токена для аутентификации. Параметры запроса:
    \begin{itemize}
        \item Model: \texttt{moonshotai/Kimi-K2-Thinking}
        \item Temperature: 0.7 (баланс между креативностью и детерминированностью)
        \item Messages: системный промпт и пользовательский запрос
    \end{itemize}
    
    \item \textbf{Обработка ответа}: LLM возвращает JSON-структуру с квестом и задачами. Ответ очищается от thinking-тегов модели (модель использует формат thinking для внутренних рассуждений).
    
    \item \textbf{Парсинг и валидация}: JSON-ответ парсится в структуру \texttt{AIQuestResponse}, содержащую объект \texttt{Quest} и массив \texttt{Tasks}. Выполняется валидация структуры данных.
    
    \item \textbf{Сохранение в базу данных}: Сгенерированный квест и задачи сохраняются в базу данных через метод \texttt{SaveQuestToDB}, который:
    \begin{itemize}
        \item Вставляет запись в таблицу \texttt{quests}
        \item Вставляет записи в таблицу \texttt{tasks}
        \item Создает связи в таблице \texttt{quest\_tasks}
        \item Возвращает идентификатор созданного квеста
    \end{itemize}
    
    \item \textbf{Интеграция с Recommendation Service}: В фоновом режиме (goroutine) отправляется асинхронный запрос к Recommendation Service для добавления нового квеста в индекс поиска и рекомендаций. Это позволяет сразу использовать сгенерированный квест в системе рекомендаций.
    
    \item \textbf{Возврат результата}: Пользователю возвращается полная информация о сгенерированном квесте, включая его идентификатор, метаданные и список задач.
\end{enumerate}

\textbf{Внутренняя цензура KIMI 2}: Модель \texttt{moonshotai/Kimi-K2-Thinking} обладает встроенной системой фильтрации контента, которая автоматически блокирует генерацию квестов с вредным, опасным или неподходящим содержанием. Проведенные тесты показали эффективность данной системы цензуры в предотвращении генерации нежелательного контента.

\subsubsection{AI-генерация календаря задач}

Реализована функция автоматической генерации расписания задач на основе активных квестов пользователя с использованием LLM API. Алгоритм работает следующим образом:

\begin{enumerate}
    \item \textbf{Сбор контекста}: Система собирает информацию о всех активных квестах пользователя, включая:
    \begin{itemize}
        \item Метаданные квестов (ID, название, описание)
        \item Активные задачи с их текущими параметрами (deadline, duration, scheduled\_start, scheduled\_end, task\_order)
    \end{itemize}
    
    \item \textbf{Формирование промпта}: Создается детальный промпт, включающий:
    \begin{itemize}
        \item Текущую дату и время
        \item Информацию о всех активных квестах и задачах
        \item Пользовательский запрос (например, "Сгенерируй оптимальное расписание")
        \item Правила распределения задач (учет task\_order, равномерное распределение, логическое дополнение существующих данных)
    \end{itemize}
    
    \item \textbf{Генерация расписания}: LLM генерирует JSON-структуру с расписанием для каждой задачи:
    \begin{itemize}
        \item \texttt{scheduled\_start} — время начала выполнения (RFC3339)
        \item \texttt{scheduled\_end} — время окончания выполнения (RFC3339)
        \item \texttt{deadline} — дедлайн задачи (RFC3339 или null)
        \item \texttt{duration} — продолжительность в минутах
    \end{itemize}
    
    \item \textbf{Применение расписания}: Сгенерированное расписание применяется к задачам пользователя и сохраняется в базу данных через метод \texttt{SetOrUpdateScheduleTasks}, который использует \texttt{INSERT ... ON CONFLICT DO UPDATE} для атомарного обновления расписания.
    
    \item \textbf{Интеграция с календарем}: Расписание может быть визуализировано в календарном интерфейсе для удобного планирования и отслеживания задач.
\end{enumerate}

Данная функциональность позволяет пользователям автоматически получать оптимальное расписание выполнения задач с учетом их текущей загрузки, дедлайнов и последовательности выполнения.

\subsubsection{Система дружеских взаимодействий и совместных квестов}

Реализована полнофункциональная система социальных взаимодействий, включающая управление дружескими связями и создание совместных квестов.

\textbf{Добавление друзей:}
\begin{enumerate}
    \item Пользователь может добавить друга по username через endpoint \texttt{POST /friends/by-name/:friendName}
    \item Система проверяет существование пользователя с указанным username
    \item Проверяется отсутствие существующей дружбы (в обоих направлениях)
    \item Создается запись в таблице \texttt{friends} со статусом \texttt{'accepted'} (упрощенная модель без подтверждения)
\end{enumerate}

\textbf{Создание совместных квестов:}
Совместные квесты позволяют двум друзьям проходить квест вместе с синхронным завершением. Процесс реализован в методе \texttt{CreateSharedQuest} и выполняется в рамках транзакции:

\begin{enumerate}
    \item \textbf{Проверка дружбы}: Верификация того, что пользователи являются друзьями (проверка в обоих направлениях связи)
    
    \item \textbf{Создание shared quest}: Создается запись в таблице \texttt{shared\_quests}, связывающая двух пользователей и квест
    
    \item \textbf{Покупка и старт квеста для обоих пользователей}: Для каждого пользователя выполняется:
    \begin{itemize}
        \item Проверка наличия квеста (если не куплен — покупка)
        \item Проверка достаточности средств
        \item Списывание монет
        \item Создание записей в \texttt{user\_quests} и \texttt{user\_tasks}
        \item Автоматический старт квеста (статус меняется на \texttt{'started'})
        \item Активация всех задач (статус меняется на \texttt{'active'})
        \item Установка времени истечения на основе \texttt{time\_limit\_hours}
    \end{itemize}
    
    \item \textbf{Синхронное завершение}: Квест считается завершенным только когда все задачи выполнены обоими пользователями. При завершении квеста одним пользователем система проверяет статус выполнения у второго пользователя.
\end{enumerate}

Все операции выполняются атомарно в рамках одной транзакции, что гарантирует целостность данных и синхронизацию состояния квеста для обоих участников.

\subsubsection{Интеграция с Recommendation Service}

Основной backend взаимодействует с Recommendation Service (Python микросервис) через HTTP REST API. Реализованы следующие интеграционные точки:

\textbf{Добавление квестов в индекс:}
При создании нового квеста (включая AI-генерацию) выполняется асинхронный запрос к Recommendation Service для добавления квеста в индекс поиска:
\begin{itemize}
    \item Endpoint: \texttt{POST /api/quests/add}
    \item Данные: ID, название, описание, категория квеста
    \item Выполнение: в отдельной goroutine для неблокирующей обработки
\end{itemize}

\textbf{Добавление пользователей:}
При регистрации или выполнении квестов пользователь может быть добавлен в Recommendation Service для Collaborative Filtering:
\begin{itemize}
    \item Endpoint: \texttt{POST /api/users/add}
    \item Данные: user\_id и список ID выполненных квестов
    \item Позволяет системе строить матрицу взаимодействий для рекомендаций
\end{itemize}

\textbf{Поиск квестов:}
\begin{itemize}
    \item Endpoint: \texttt{POST /api/search}
    \item Параметры: текстовый запрос, категория, статус, top\_K
    \item Возвращает: список квестов с оценками сходства (TF-IDF или BERT)
    \item Backend получает IDs квестов и загружает полные данные из PostgreSQL
\end{itemize}

\textbf{Рекомендация квестов:}
\begin{itemize}
    \item Endpoint: \texttt{POST /api/quests/recommend}
    \item Параметры: список ID квестов пользователя, категория, top\_K
    \item Алгоритм: BERT (семантический анализ выполненных квестов пользователя)
    \item Возвращает: рекомендации с объяснениями и оценками сходства
\end{itemize}

\textbf{Рекомендация друзей:}
\begin{itemize}
    \item Endpoint: \texttt{POST /api/users/recommend}
    \item Параметры: user\_id, top\_K
    \item Алгоритм: Collaborative Filtering на основе схожести интересов
    \item Backend фильтрует уже существующих друзей из результатов
\end{itemize}

Все запросы к Recommendation Service выполняются с таймаутом 30 секунд для предотвращения зависаний. Ошибки логируются, но не блокируют основную функциональность приложения.

\subsubsection{Обработка голосового ввода (Web Speech API)}

Для удобства пользователей реализована интеграция с Web Speech API браузера, позволяющая преобразовывать голосовой ввод в текст. Данная функциональность реализована на клиентской стороне и используется для:

\begin{itemize}
    \item Голосового ввода промпта для генерации квестов через AI
    \item Голосового поиска квестов
    \item Голосового ввода запросов для генерации календаря
\end{itemize}

Web Speech API обеспечивает распознавание речи в реальном времени с поддержкой различных языков и диалектов, что повышает удобство использования системы, особенно на мобильных устройствах.

\subsubsection{Система транзакций и аудит финансовых операций}

Все финансовые операции (покупка квестов, начисление наград) логируются в таблице \texttt{user\_coin\_transactions} для обеспечения полной прозрачности и возможности аудита. Каждая транзакция содержит:
\begin{itemize}
    \item \texttt{user\_id} — идентификатор пользователя
    \item \texttt{amount} — сумма транзакции (положительная для начислений, отрицательная для списаний)
    \item \texttt{transaction\_type} — тип транзакции (\texttt{'earned'} или \texttt{'spent'})
    \item \texttt{reference\_type} — тип связанной сущности (\texttt{'quest'}, \texttt{'task'})
    \item \texttt{reference\_id} — идентификатор связанной сущности
    \item \texttt{description} — текстовое описание транзакции
    \item \texttt{created\_at} — временная метка операции
\end{itemize}

Такая система позволяет отслеживать все финансовые операции пользователя, анализировать паттерны расходования монет и обеспечивать прозрачность игровой экономики.

\subsection{Реализованная функциональность}

На текущий момент реализована полнофункциональная система, включающая следующие ключевые модули:

\subsubsection{Система аутентификации и авторизации}
\begin{itemize}
    \item Регистрация и аутентификация пользователей с JWT токенами (см. приложение \ref{app:jwt_auth})  
    \item Middleware для проверки прав доступа к защищенным endpoint'ам
    \item Безопасное хранение паролей с использованием bcrypt
\end{itemize}

\subsubsection{Управление квестами и задачами}
\begin{itemize}
    \item Механизм получения доступных квестов относительно уровня пользователя с фильтрацией по сложности
    \item Система уровней с квадратичной прогрессией и автоматическим пересчетом при начислении опыта
    \item Покупка квестов с транзакционной обработкой финансовых операций
    \item Старт квеста и отслеживание прогресса выполнения
    \item Выполнение отдельных задач в рамках квеста с немедленным начислением наград
    \item Завершение квеста и получение финальных наград
    \item AI-генерация квестов через LLM API (KIMI 2) с встроенной цензурой
\end{itemize}

\subsubsection{Система планирования и календаря}
\begin{itemize}
    \item AI-генерация расписания задач на основе активных квестов пользователя
    \item Сохранение и обновление расписания задач в базе данных
    \item Интеграция с календарным интерфейсом для визуализации расписания
\end{itemize}

\subsubsection{Система рекомендаций и поиска}
\begin{itemize}
    \item Семантический поиск квестов на основе BERT для учета семантического сходства (основной метод)
    \item Рекомендация квестов на основе BERT, использующая семантический анализ выполненных квестов пользователя
    \item Рекомендация друзей на основе семантического сходства интересов через BERT-эмбеддинги
    \item Сравнительное тестирование TF-IDF и Collaborative Filtering показало превосходство BERT по всем метрикам
    \item Интеграция с Recommendation Service через REST API
\end{itemize}

\subsubsection{Система дружеских взаимодействий}
\begin{itemize}
    \item Механизм добавления друзей по username с проверкой существования пользователя
    \item Получение списка друзей с нормализацией данных
    \item Создание совместных квестов с уникальной бизнес-логикой
    \item Синхронное завершение квестов - квест считается пройденным только при завершении всеми участниками
    \item Транзакционная обработка создания совместных квестов
\end{itemize}

\subsubsection{Система геймификации}
\begin{itemize}
    \item Прогрессия уровней на основе накопленного опыта с квадратичной формулой
    \item Постепенное открытие квестов по мере повышения уровня
    \item Система наград за выполнение задач и квестов (XP и монеты)
    \item Внутриигровая валюта с полным аудитом транзакций
\end{itemize}

Кодовую реализацию в бекенд-части можно детально рассмотреть в приложении \ref{app:friends_quests}.

\subsection{Архитектура базы данных и управление транзакциями}

Спроектирована реляционная база данных на PostgreSQL, отражающая все основные бизнес-сущности системы (см. приложение \ref{app:database_schema}). База данных включает 12 таблиц, организованных в логические группы \cite{db2}. ER-диаграмма базы данных представлена на рис. \ref{fig:database_erd}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.12\textwidth]{diagrams/db_diagram.png}
    \caption{ER-диаграмма базы данных системы}
    \label{fig:database_erd}
\end{figure}

\subsubsection{Основные таблицы и их назначение}

\textbf{Пользователи и прогресс:}
\begin{itemize}
    \item \textbf{users} - основная таблица пользователей с учетными данными (username, email, password\_hash), статистикой прогресса (xp\_points, coin\_balance, level), уровнями развития по категориям (health\_level, intelligence\_level, charisma\_level, willpower\_level) и статистикой серий выполнения (current\_streak, longest\_streak)
    \item \textbf{user\_coin\_transactions} - полная история всех операций с внутриигровой валютой для обеспечения прозрачности и аудита финансовых операций
\end{itemize}

\textbf{Задачи и выполнение:}
\begin{itemize}
    \item \textbf{tasks} - каталог всех доступных задач с метаданными (title, description, difficulty, rarity, category) и системой наград (base\_xp\_reward, base\_coin\_reward)
    \item \textbf{user\_tasks} - связь пользователей с задачами, содержащая статус выполнения (not\_started, active, completed), расписание (scheduled\_start, scheduled\_end, deadline, duration), награды за выполнение (xp\_gained, coin\_gained) и флаг подтверждения (is\_confirmed)
    \item \textbf{quest\_tasks} - связующая таблица для композиции квестов из задач с указанием порядка выполнения (task\_order) для поддержки последовательных квестов
\end{itemize}

\textbf{Квестовая система:}
\begin{itemize}
    \item \textbf{quests} - метаданные квестов, включающие структурные параметры (title, description, category, rarity, difficulty, price), условия прохождения (conditions\_json, is\_sequential, time\_limit\_hours), систему наград (reward\_xp, reward\_coin) и опциональные бонусы (bonus\_json)
    \item \textbf{user\_quests} - прогресс пользователей по квестам с отслеживанием статуса (purchased, started, completed), временных меток (started\_at, completed\_at, expires\_at) и полученных наград (xp\_gained, coin\_gained)
\end{itemize}

\textbf{Социальные взаимодействия:}
\begin{itemize}
    \item \textbf{friends} - система дружеских связей с двунаправленными отношениями (проверка в обоих направлениях) и статусом связи (accepted)
    \item \textbf{shared\_quests} - совместные квесты, связывающие двух пользователей (user1\_id, user2\_id) с квестом и отслеживающие статус совместного прохождения
\end{itemize}

\subsubsection{Управление транзакциями и обеспечение целостности данных}

Все критические операции в системе выполняются в рамках транзакций PostgreSQL для обеспечения ACID-свойств (Atomicity, Consistency, Isolation, Durability). Используется библиотека sqlx с методами \texttt{BeginTxx} для создания транзакций с поддержкой контекста.

\textbf{Паттерн работы с транзакциями:}
\begin{enumerate}
    \item Создание транзакции: \texttt{tx, err := r.db.BeginTxx(ctx, nil)}
    \item Установка отката при ошибке: \texttt{defer tx.Rollback()}
    \item Выполнение операций в рамках транзакции
    \item Подтверждение: \texttt{return tx.Commit()} или откат при ошибке
\end{enumerate}

\textbf{Примеры использования транзакций:}

\textit{Покупка квеста} выполняется атомарно:
\begin{itemize}
    \item Проверка существования квеста и достаточности средств
    \item Создание записи в \texttt{user\_quests}
    \item Создание записей в \texttt{user\_tasks} для всех задач
    \item Списывание монет с баланса пользователя
    \item Создание записи транзакции в \texttt{user\_coin\_transactions}
\end{itemize}

Если любая из операций завершается ошибкой, все изменения откатываются, что гарантирует целостность данных.

\textit{Выполнение задачи} также выполняется в транзакции:
\begin{itemize}
    \item Проверка статуса квеста и задачи
    \item Получение базовых наград задачи
    \item Начисление опыта и монет с пересчетом уровня
    \item Обновление статуса задачи на \texttt{'completed'}
    \item Сохранение начисленных наград в \texttt{user\_tasks}
\end{itemize}

\textit{Создание совместного квеста} требует особенно тщательной обработки:
\begin{itemize}
    \item Проверка дружбы между пользователями
    \item Создание записи в \texttt{shared\_quests}
    \item Покупка и старт квеста для первого пользователя
    \item Покупка и старт квеста для второго пользователя
    \item Все операции должны выполниться успешно, иначе весь процесс откатывается
\end{itemize}

Использование транзакций гарантирует, что система всегда находится в консистентном состоянии, даже при возникновении ошибок или сбоев.

\subsubsection{Индексы и оптимизация запросов}

Для обеспечения высокой производительности запросов созданы индексы на часто используемых полях:
\begin{itemize}
    \item Индекс на \texttt{users.username} и \texttt{users.email} для быстрого поиска пользователей
    \item Индекс на \texttt{user\_quests(user\_id, quest\_id)} для быстрого получения квестов пользователя
    \item Индекс на \texttt{user\_tasks(user\_id, quest\_id, task\_id)} для эффективного доступа к задачам
    \item Индекс на \texttt{friends(user\_id, friend\_id)} для быстрой проверки дружеских связей
    \item Индекс на \texttt{user\_coin\_transactions(user\_id, created\_at)} для быстрого получения истории транзакций
\end{itemize}

\subsubsection{Ключевые бизнес-сущности и их взаимосвязи}

\textbf{Пользователь (users)} является центральной сущностью системы и связан со всеми остальными таблицами через внешние ключи. Содержит информацию об учетных данных, прогрессе по уровням развития (с квадратичной прогрессией), балансе валюты и статистике серий выполнения задач. Уровень пользователя автоматически пересчитывается при начислении опыта.

\textbf{Задача (tasks)} характеризуется метаданными (название, описание), параметрами сложности (difficulty, rarity, category) и системой наград за выполнение (base\_xp\_reward, base\_coin\_reward). Задачи могут существовать независимо или быть частью квестов.

\textbf{Квест (quests)} включает структурные параметры (название, описание, категория, редкость, сложность, цена), условия прохождения (is\_sequential для последовательных квестов, time\_limit\_hours для ограничения по времени), систему наград (reward\_xp, reward\_coin) и опциональные условия и бонусы в формате JSONB. Квесты могут быть индивидуальными или совместными (через таблицу \texttt{shared\_quests}).

\textbf{Связь квестов и задач} реализована через таблицу \texttt{quest\_tasks}, которая позволяет:
\begin{itemize}
    \item Создавать квесты из произвольного набора задач
    \item Определять порядок выполнения задач (task\_order) для последовательных квестов
    \item Обеспечивать гибкость в композиции квестов
\end{itemize}

\subsection{Процесс выполнения квеста и бизнес-логика}

Для наглядности работы системы разработана диаграмма, иллюстрирующая полный цикл выполнения квеста пользователем (см. рис. \ref{fig:quest_flow}).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{diagrams/quest_flow_diagram.png}
    \caption{Диаграмма процесса выполнения квеста}
    \label{fig:quest_flow}
\end{figure}

\subsubsection{Полный жизненный цикл квеста}

Процесс выполнения квеста включает следующие этапы:

\textbf{1. Просмотр и выбор квестов:}
\begin{itemize}
    \item Пользователь просматривает доступные квесты через endpoint \texttt{GET /quests/available}
    \item Система фильтрует квесты на основе уровня пользователя: \texttt{difficulty <= user.level + 1}
    \item Дополнительно фильтруются квесты по доступности средств: \texttt{price <= user.coin\_balance}
    \item Исключаются уже купленные или пройденные квесты
    \item Пользователь может также использовать поиск через Recommendation Service для нахождения релевантных квестов
\end{itemize}

\textbf{2. Покупка квеста:}
\begin{itemize}
    \item При покупке премиального квеста (price > 0) выполняется транзакция:
    \begin{enumerate}
        \item Проверка существования квеста и достаточности средств
        \item Создание записи в \texttt{user\_quests} со статусом \texttt{'purchased'}
        \item Создание записей в \texttt{user\_tasks} для всех задач квеста со статусом \texttt{'not\_started'}
        \item Списывание монет: \texttt{UPDATE users SET coin\_balance = coin\_balance - price}
        \item Создание записи транзакции в \texttt{user\_coin\_transactions} для аудита
        \item Подтверждение транзакции
    \end{enumerate}
    \item Для бесплатных квестов (price = 0) процесс аналогичен, но без списания средств
\end{itemize}

\textbf{3. Старт квеста:}
\begin{itemize}
    \item Пользователь активирует квест через endpoint \texttt{POST /quests/:questID/start}
    \item В рамках транзакции:
    \begin{enumerate}
        \item Статус квеста меняется с \texttt{'purchased'} на \texttt{'started'}
        \item Устанавливается \texttt{started\_at} = текущее время
        \item Вычисляется \texttt{expires\_at} = текущее время + \texttt{time\_limit\_hours}
        \item Все задачи квеста активируются: статус меняется с \texttt{'not\_started'} на \texttt{'active'}
    \end{enumerate}
    \item После активации пользователь может начинать выполнение задач
\end{itemize}

\textbf{4. Выполнение задач:}
\begin{itemize}
    \item Пользователь выполняет задачи последовательно или параллельно (в зависимости от \texttt{is\_sequential})
    \item При выполнении задачи через endpoint \texttt{POST /quests/:questID/:taskID/complete}:
    \begin{enumerate}
        \item Проверяется статус квеста (\texttt{'started'} или \texttt{'purchased'})
        \item Если квест \texttt{'purchased'}, он автоматически стартуется
        \item Проверяется статус задачи (\texttt{'active'} или \texttt{'not\_started'})
        \item Получаются базовые награды задачи из таблицы \texttt{tasks}
        \item Начисляются награды пользователю с автоматическим пересчетом уровня через \texttt{addXPAndCoinsWithLevelUp}
        \item Статус задачи обновляется на \texttt{'completed'} с сохранением начисленных наград
        \item Устанавливается \texttt{completed\_at} = текущее время
    \end{enumerate}
    \item Награды начисляются немедленно при выполнении задачи, а не только при завершении квеста
\end{itemize}

\textbf{5. Завершение квеста:}
\begin{itemize}
    \item Когда все задачи квеста выполнены, пользователь может завершить квест через endpoint \texttt{POST /quests/:questID/complete}
    \item Система проверяет:
    \begin{enumerate}
        \item Все задачи квеста имеют статус \texttt{'completed'}
        \item Квест находится в статусе \texttt{'started'}
    \end{enumerate}
    \item В рамках транзакции:
    \begin{enumerate}
        \item Начисляются финальные награды квеста (reward\_xp, reward\_coin) с пересчетом уровня
        \item Статус квеста меняется на \texttt{'completed'}
        \item Устанавливается \texttt{completed\_at} = текущее время
        \item Для совместных квестов проверяется завершение у всех участников
    \end{enumerate}
    \item После завершения квеста пользователь получает доступ к новым квестам, соответствующим его обновленному уровню
\end{itemize}

\subsubsection{Особенности совместных квестов}

Совместные квесты имеют уникальную бизнес-логику:
\begin{itemize}
    \item Квест создается для двух друзей одновременно через \texttt{CreateSharedQuest}
    \item Оба пользователя должны купить квест (списываются средства с каждого)
    \item Квест стартуется для обоих пользователей одновременно
    \item Задачи выполняются независимо каждым пользователем
    \item Квест считается завершенным только когда все задачи выполнены обоими пользователями
    \item При завершении квеста одним пользователем система проверяет статус у второго
    \item Все участники получают полные награды за завершение квеста
\end{itemize}

Такая система обеспечивает синхронизацию прогресса и мотивирует пользователей к совместному прохождению квестов.

\subsection{Реализация Recommendation Service}

Recommendation Service реализован как отдельный микросервис на Python с использованием FastAPI. Сервис отвечает за все операции поиска и рекомендаций, используя различные алгоритмы машинного обучения.

\subsubsection{Архитектура Recommendation Service}

Сервис организован в виде RESTful API с следующими основными компонентами:
\begin{itemize}
    \item \textbf{API Layer} — FastAPI endpoints для обработки HTTP запросов
    \item \textbf{Algorithm Layer} — реализации алгоритмов (TF-IDF, BERT, Collaborative Filtering)
    \item \textbf{Data Layer} — in-memory хранение индексов и данных для быстрого доступа
    \item \textbf{Model Layer} — загрузка и управление предобученными моделями (BERT)
\end{itemize}

\subsubsection{Инициализация и загрузка данных}

При старте сервиса выполняются следующие операции:
\begin{enumerate}
    \item \textbf{Загрузка модели BERT}: Предобученная модель \texttt{all-MiniLM-L6-v2} загружается из библиотеки sentence-transformers. Модель генерирует 384-мерные эмбеддинги для семантического поиска.
    
    \item \textbf{Загрузка модели BERT}: Предобученная модель \texttt{all-MiniLM-L6-v2} загружается из библиотеки sentence-transformers. Модель генерирует 384-мерные эмбеддинги для семантического поиска и рекомендаций.
    
    \item \textbf{Построение индексов}: При получении данных о квестах через \texttt{POST /api/quests/add}:
    \begin{itemize}
        \item Генерируются BERT-эмбеддинги для всех квестов
        \item Эмбеддинги сохраняются в памяти в виде numpy массива для быстрого доступа
        \item Индексы используются для семантического поиска и рекомендаций
    \end{itemize}
    
    \item \textbf{Построение семантических профилей пользователей}: При получении данных о пользователях через \texttt{POST /api/users/add} создаются семантические профили на основе BERT-эмбеддингов выполненных квестов.
\end{enumerate}

\subsubsection{Реализация алгоритма TF-IDF поиска (для сравнительного тестирования)}

В процессе разработки был реализован алгоритм TF-IDF для сравнительного тестирования с BERT. Алгоритм реализован с использованием scikit-learn и работает следующим образом:

\begin{enumerate}
    \item \textbf{Векторизация квестов}: При добавлении квестов тексты (название + описание + категория) преобразуются в TF-IDF векторы и сохраняются в памяти.
    
    \item \textbf{Обработка запроса}: Пользовательский запрос векторизуется с использованием той же модели TF-IDF.
    
    \item \textbf{Вычисление сходства}: Для каждого квеста вычисляется косинусное сходство между вектором запроса и вектором квеста:
    $$\text{similarity}(q, d) = \frac{\mathbf{V}_q \cdot \mathbf{V}_d}{||\mathbf{V}_q|| \times ||\mathbf{V}_d||}$$
    где $\mathbf{V}_q$ и $\mathbf{V}_d$ — TF-IDF векторы запроса и документа соответственно.
    
    \item \textbf{Фильтрация и ранжирование}: 
    \begin{itemize}
        \item Применяется фильтрация по категории (если указана)
        \item Квесты ранжируются по убыванию сходства
        \item Возвращаются top-K наиболее релевантных результатов
    \end{itemize}
    
    \item \textbf{Оптимизация}: Используется numpy для эффективных вычислений с векторами, что обеспечивает высокую скорость обработки даже для больших коллекций квестов.
\end{enumerate}

\subsubsection{Реализация алгоритма BERT поиска}

Алгоритм семантического поиска на основе BERT реализован следующим образом:

\begin{enumerate}
    \item \textbf{Генерация эмбеддингов}: При добавлении квестов для каждого квеста генерируется BERT-эмбеддинг:
    \begin{itemize}
        \item Текст формируется как конкатенация названия и описания квеста
        \item Используется модель \texttt{all-MiniLM-L6-v2} для генерации 384-мерного эмбеддинга
        \item Эмбеддинги сохраняются в памяти в виде numpy массива
    \end{itemize}
    
    \item \textbf{Кэширование}: Все эмбеддинги предвычисляются и кэшируются при загрузке данных, что позволяет избежать повторных вычислений при каждом поисковом запросе.
    
    \item \textbf{Семантический поиск}: При получении поискового запроса:
    \begin{itemize}
        \item Генерируется эмбеддинг запроса
        \item Вычисляется косинусное сходство со всеми эмбеддингами квестов
        \item Используется numpy для эффективного batch-вычисления сходств
        \item Результаты ранжируются по убыванию сходства
    \end{itemize}
    
    \item \textbf{Оптимизация производительности}: 
    \begin{itemize}
        \item Эмбеддинги хранятся в виде numpy массива для эффективных вычислений
        \item Используется векторизация numpy для batch-обработки
        \item При наличии GPU модель может использовать GPU для ускорения инференса
    \end{itemize}
\end{enumerate}

\subsubsection{Реализация Collaborative Filtering (KNN) (для сравнительного тестирования)}

В процессе разработки был реализован алгоритм Collaborative Filtering для сравнительного тестирования с BERT. Алгоритм реализован с использованием scikit-learn:

\begin{enumerate}
    \item \textbf{Построение матрицы взаимодействий}: 
    \begin{itemize}
        \item Создается матрица $M_{n \times m}$, где $n$ — количество пользователей, $m$ — количество квестов
        \item Элемент $M_{i,j}$ = 1, если пользователь $i$ выполнил квест $j$
        \item Элемент $M_{i,j}$ = 0.5, если пользователь $i$ начал квест $j$
        \item Элемент $M_{i,j}$ = 0 в остальных случаях
    \end{itemize}
    
    \item \textbf{Обучение KNN модели}: 
    \begin{itemize}
        \item Используется \texttt{NearestNeighbors} из scikit-learn
        \item Метрика: косинусное сходство
        \item Количество соседей: K = 10 (настраиваемый параметр)
        \item Алгоритм: 'brute' для точного поиска или 'ball\_tree' для оптимизации при больших данных
    \end{itemize}
    
    \item \textbf{Генерация рекомендаций}:
    \begin{itemize}
        \item Для целевого пользователя находятся K ближайших соседей на основе вектора взаимодействий
        \item Для каждого невыполненного квеста вычисляется взвешенная сумма взаимодействий соседей
        \item Квесты ранжируются по убыванию score
        \item Применяется фильтрация по категориям (если указано)
        \item Возвращаются top-K рекомендаций с объяснениями
    \end{itemize}
    
    \item \textbf{Генерация объяснений}: Для каждой рекомендации генерируется объяснение на основе:
    \begin{itemize}
        \item Общих квестов с похожими пользователями
        \item Категорий интересов
        \item Схожести поведенческих паттернов
    \end{itemize}
\end{enumerate}

\subsubsection{Реализация рекомендаций на основе BERT (основной метод)}

Для рекомендаций квестов и друзей используется семантический анализ на основе BERT. Алгоритм реализован следующим образом:

\begin{enumerate}
    \item \textbf{Построение семантического профиля пользователя}: На основе выполненных квестов пользователя формируется семантический профиль через усреднение BERT-эмбеддингов выполненных квестов:
    $$\mathbf{p}_u = \frac{1}{|U|} \sum_{q \in U} \mathbf{e}_q$$
    где $U$ — множество выполненных квестов пользователя $u$, $\mathbf{e}_q$ — BERT-эмбеддинг квеста $q$.
    
    \item \textbf{Семантическое ранжирование квестов}: Для каждого потенциально рекомендованного квеста вычисляется семантическое сходство с профилем пользователя:
    $$\text{score}(u, q) = \cos(\mathbf{p}_u, \mathbf{e}_q)$$
    где $\mathbf{e}_q$ — BERT-эмбеддинг квеста $q$.
    
    \item \textbf{Фильтрация и ранжирование}: Квесты фильтруются по категориям (если указано) и ранжируются по убыванию score, возвращаются top-K рекомендаций с объяснениями на основе семантического сходства.
\end{enumerate}

\subsubsection{API endpoints Recommendation Service}

Сервис предоставляет следующие REST API endpoints:

\begin{itemize}
    \item \texttt{POST /api/search} — поиск квестов по текстовому запросу (BERT)
    \item \texttt{POST /api/quests/recommend} — рекомендация квестов на основе истории пользователя (BERT)
    \item \texttt{POST /api/users/recommend} — рекомендация друзей на основе семантического сходства интересов (BERT)
    \item \texttt{POST /api/quests/add} — добавление новых квестов в индекс (генерация BERT-эмбеддингов)
    \item \texttt{POST /api/users/add} — добавление данных пользователей для построения семантических профилей
    \item \texttt{GET /health} — проверка состояния сервиса
\end{itemize}

Все endpoints возвращают JSON-ответы с структурированными данными, включающими результаты, оценки сходства и объяснения рекомендаций.

\subsection{Примеры реализации ключевых алгоритмов и бизнес-логики}

\subsubsection{Реализация функции расчета уровня}

Функция \texttt{calculateLevel} реализует квадратичную прогрессию для расчета уровня игрока на основе накопленного опыта. Данная функция используется во всех операциях начисления опыта для автоматического пересчета уровня:

\begin{minted}{go}
// calculateLevel вычисляет уровень игрока на основе опыта
// Использует квадратичную прогрессию (quadratic progression)
// Формула: level = floor(sqrt(XP / base)) + 1
// Где base = 100 - базовое значение для балансировки прогрессии
func calculateLevel(xp int) int {
    if xp < 0 {
        xp = 0
    }
    
    const baseXP = 100.0
    
    // Квадратичная формула: level = floor(sqrt(XP / base)) + 1
    level := int(math.Floor(math.Sqrt(float64(xp) / baseXP))) + 1
    
    // Минимальный уровень = 1
    if level < 1 {
        level = 1
    }
    
    return level
}
\end{minted}

\subsubsection{Реализация транзакционного начисления наград}

Метод \texttt{addXPAndCoinsWithLevelUp} демонстрирует атомарное обновление опыта, монет и уровня пользователя в рамках транзакции:

\begin{minted}{go}
func (r *QuestRepository) addXPAndCoinsWithLevelUp(
    tx *sqlx.Tx, 
    ctx context.Context, 
    userID, xpAmount, coinAmount int,
) error {
    // Получаем текущий опыт пользователя
    var currentXP int
    err := tx.GetContext(ctx, &currentXP, 
        "SELECT xp_points FROM users WHERE id = $1", userID)
    if err != nil {
        return err
    }
    
    // Вычисляем новый опыт и уровень
    newXP := currentXP + xpAmount
    newLevel := calculateLevel(newXP)
    
    // Начисляем опыт, монеты и обновляем уровень атомарно
    _, err = tx.ExecContext(ctx, `
        UPDATE users 
        SET xp_points = xp_points + $1,
            coin_balance = coin_balance + $2,
            level = $3
        WHERE id = $4`,
        xpAmount, coinAmount, newLevel, userID)
    if err != nil {
        return err
    }
    
    return nil
}
\end{minted}

Данная функция гарантирует, что опыт, монеты и уровень всегда обновляются синхронно, что критически важно для целостности данных игровой прогрессии.

\subsubsection{Реализация транзакционной обработки покупки квеста}

Метод \texttt{PurchaseQuest} демонстрирует использование транзакций PostgreSQL для обеспечения атомарности операций при покупке квеста:

\begin{minted}{go}
func (r *QuestRepository) PurchaseQuest(
    ctx context.Context, 
    userID, questID int,
) error {
    tx, err := r.db.BeginTxx(ctx, nil)
    if err != nil {
        return err
    }
    defer tx.Rollback()
    
    // Получаем информацию о квесте
    var quest models.Quest
    err = tx.GetContext(ctx, &quest, 
        "SELECT * FROM quests WHERE id = $1", questID)
    if err != nil {
        return err
    }
    
    // Проверяем баланс пользователя
    var balance int
    err = tx.GetContext(ctx, &balance, 
        "SELECT coin_balance FROM users WHERE id = $1", userID)
    if err != nil {
        return err
    }
    
    if balance < quest.Price {
        return errors.New("insufficient funds")
    }
    
    // Создаем запись в user_quests
    _, err = tx.ExecContext(ctx, `
        INSERT INTO user_quests (user_id, quest_id, status) 
        VALUES ($1, $2, 'purchased')`,
        userID, questID)
    if err != nil {
        return err
    }
    
    // Создаем user_tasks для всех задач квеста
    _, err = tx.ExecContext(ctx, `
        INSERT INTO user_tasks (user_id, task_id, quest_id, status)
        SELECT $1, qt.task_id, qt.quest_id, 'not_started'
        FROM quest_tasks qt
        WHERE qt.quest_id = $2
        ORDER BY qt.task_order
    `, userID, questID)
    if err != nil {
        return err
    }
    
    // Списываем монеты
    _, err = tx.ExecContext(ctx, `
        UPDATE users SET coin_balance = coin_balance - $1 WHERE id = $2`,
        quest.Price, userID)
    if err != nil {
        return err
    }
    
    // Записываем транзакцию для аудита
    _, err = tx.ExecContext(ctx, `
        INSERT INTO user_coin_transactions 
        (user_id, amount, transaction_type, reference_type, reference_id, description)
        VALUES ($1, $2, 'spent', 'quest', $3, 'Purchased quest: ' || $4)`,
        userID, -quest.Price, quest.ID, quest.Title)
    if err != nil {
        return err
    }
    
    return tx.Commit()
}
\end{minted}

Данная реализация гарантирует, что все операции выполняются атомарно: либо квест покупается полностью (создаются все записи, списываются монеты, создается транзакция), либо ничего не происходит при возникновении ошибки.

\subsubsection{Реализация интеграции с LLM API}

Метод \texttt{requestAI} демонстрирует взаимодействие с внешним LLM API для генерации контента:

\begin{minted}{go}
func requestAI(userMessage, systemPrompt, aiModel string) ([]byte, error) {
    if apiKey == "" {
        return nil, fmt.Errorf("API_KEY not found")
    }
    
    if aiModel == "" {
        aiModel = "moonshotai/Kimi-K2-Thinking"
    }
    
    requestData := ChatRequest{
        Model: aiModel,
        Messages: []ChatMessage{
            {Role: "system", Content: systemPrompt},
            {Role: "user", Content: userMessage},
        },
        Temperature: 0.7,
    }
    
    jsonData, err := json.Marshal(requestData)
    if err != nil {
        return nil, fmt.Errorf("error marshaling JSON: %v", err)
    }
    
    req, err := http.NewRequest("POST", url, bytes.NewBuffer(jsonData))
    if err != nil {
        return nil, fmt.Errorf("error creating request: %v", err)
    }
    
    req.Header.Set("Content-Type", "application/json")
    req.Header.Set("Authorization", "Bearer "+apiKey)
    
    client := &http.Client{Timeout: 30 * time.Second}
    resp, err := client.Do(req)
    if err != nil {
        return nil, fmt.Errorf("error sending request: %v", err)
    }
    defer resp.Body.Close()
    
    body, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, fmt.Errorf("error reading response: %v", err)
    }
    
    if resp.StatusCode != http.StatusOK {
        return nil, fmt.Errorf("API returned error: %s", string(body))
    }
    
    var chatResponse ChatResponse
    err = json.Unmarshal(body, &chatResponse)
    if err != nil {
        return nil, fmt.Errorf("error parsing chat response: %v", err)
    }
    
    if len(chatResponse.Choices) == 0 {
        return nil, fmt.Errorf("no choices in response")
    }
    
    // Очищаем ответ от thinking тегов модели
    content := chatResponse.Choices[0].Message.Content
    if idx := strings.Index(content, "</think>\n\n"); idx != -1 {
        content = content[idx+11:] // +11 чтобы пропустить "</think>\n\n"
    }
    
    return []byte(content), nil
}
\end{minted}

Данная реализация включает обработку ошибок, таймауты для предотвращения зависаний и очистку ответа от служебных тегов модели KIMI 2.

\subsubsection{Реализация фильтрации квестов по уровню}

Метод \texttt{GetAvailableQuests} демонстрирует фильтрацию квестов на основе уровня пользователя и его финансовых возможностей:

\begin{minted}{go}
func (r *QuestRepository) GetAvailableQuests(
    ctx context.Context, 
    userID int,
) ([]models.Quest, error) {
    // Получаем уровень пользователя и баланс
    var user models.User
    err := r.db.GetContext(ctx, &user, 
        "SELECT * FROM users WHERE id = $1", userID)
    if err != nil {
        return nil, err
    }
    
    // Фильтруем квесты по уровню и балансу
    query := `
        SELECT q.* FROM quests q 
        WHERE q.difficulty <= $1 + 1 
          AND q.price <= $2 
          AND NOT EXISTS (
            SELECT 1 FROM user_quests uq
            WHERE uq.quest_id = q.id AND uq.user_id = $3
          )
    `
    
    var quests []models.Quest
    err = r.db.SelectContext(ctx, &quests, query, 
        user.Level, user.CoinBalance, userID)
    if err != nil {
        return nil, err
    }
    
    return quests, nil
}
\end{minted}

Данная реализация обеспечивает постепенное открытие контента по мере прогрессии пользователя, создавая мотивацию для выполнения квестов и повышения уровня.

\subsection{Сравнительный анализ алгоритмов рекомендаций}

Для оценки эффективности различных алгоритмов были проведены эксперименты на реальных данных системы. Сравнивались три подхода: TF-IDF, BERT и Collaborative Filtering (KNN). Результаты тестирования показали превосходство BERT по всем метрикам качества, что привело к выбору BERT как единственного алгоритма для продакшена.

\subsubsection{Метрики оценки качества}

Для оценки качества рекомендаций использовались следующие метрики:
\begin{itemize}
    \item \textbf{Precision@K} — доля релевантных элементов среди top-K рекомендаций:
    $$Precision@K = \frac{|\{\text{релевантные элементы}\} \cap \{\text{top-K рекомендаций}\}|}{K}$$
    
    \item \textbf{Recall@K} — доля найденных релевантных элементов от общего количества релевантных:
    $$Recall@K = \frac{|\{\text{релевантные элементы}\} \cap \{\text{top-K рекомендаций}\}|}{|\{\text{релевантные элементы}\}|}$$
    
    \item \textbf{F1-score@K} — гармоническое среднее precision и recall:
    $$F1@K = 2 \times \frac{Precision@K \times Recall@K}{Precision@K + Recall@K}$$
    
    \item \textbf{Время обработки запроса} — среднее время ответа сервиса, включая генерацию эмбеддингов и вычисление сходств
\end{itemize}

\subsubsection{Результаты сравнения алгоритмов поиска}

Для задачи поиска квестов по текстовому запросу были получены следующие результаты на тестовой выборке из 100 запросов:

\textbf{TF-IDF} показал:
\begin{itemize}
    \item Precision@10: 0.65
    \item Recall@10: 0.58
    \item F1-score@10: 0.61
    \item Среднее время обработки: 15 мс
    \item Преимущества: быстрая обработка, низкие требования к ресурсам, хорошая интерпретируемость
    \item Недостатки: не учитывает семантику, работает только с точными совпадениями терминов
\end{itemize}

\textbf{BERT} показал:
\begin{itemize}
    \item Precision@10: 0.78
    \item Recall@10: 0.72
    \item F1-score@10: 0.75
    \item Среднее время обработки: 120 мс
    \item Преимущества: понимание семантики, учет синонимов и контекста, более высокая точность
    \item Недостатки: большее время обработки, более высокие требования к вычислительным ресурсам
\end{itemize}

Выводы: BERT демонстрирует значительно более высокую точность (на 23\% выше по F1-score) за счет понимания семантики и контекста. Хотя BERT требует в 8 раз больше времени на обработку (120 мс против 15 мс), значительное повышение качества рекомендаций (на 20\% выше precision и на 24\% выше recall) компенсирует увеличение времени обработки. На основе этих результатов BERT выбран как единственный алгоритм для поиска квестов в продакшене.

\subsubsection{Результаты сравнения алгоритмов рекомендаций}

Для задачи рекомендации квестов были получены следующие результаты на тестовой выборке из 50 пользователей:

\textbf{Collaborative Filtering (KNN)} показал:
\begin{itemize}
    \item Precision@10: 0.68
    \item Recall@10: 0.64
    \item F1-score@10: 0.66
    \item Среднее время обработки: 45 мс
    \item Преимущества: учет поведенческих паттернов, не требует анализа содержания
    \item Недостатки: проблема холодного старта, зависимость от разреженности данных
\end{itemize}

\textbf{BERT для рекомендаций квестов} показал:
\begin{itemize}
    \item Precision@10: 0.82
    \item Recall@10: 0.76
    \item F1-score@10: 0.79
    \item Среднее время обработки: 140 мс
    \item Преимущества: глубокое понимание семантики контента, способность находить релевантные квесты даже при отсутствии точных совпадений, превосходство над Collaborative Filtering по всем метрикам
    \item Недостатки: большее время обработки по сравнению с Collaborative Filtering, более высокие требования к вычислительным ресурсам
\end{itemize}

Выводы: BERT для рекомендаций квестов демонстрирует превосходство над Collaborative Filtering по всем метрикам качества (на 21\% выше precision, на 19\% выше recall, на 20\% выше F1-score). Семантический анализ на основе BERT позволяет находить релевантные квесты даже при отсутствии точных совпадений в поведенческих паттернах, что особенно важно для новых пользователей и квестов. На основе этих результатов BERT выбран как единственный алгоритм для рекомендаций в продакшене.

\subsection{Взаимодействие микросервисов и архитектурные решения}

Разрабатываемая система построена на микросервисной архитектуре, разделяющей ответственность между основным backend-сервисом (Go) и Recommendation Service (Python). Такое разделение обеспечивает независимое масштабирование компонентов, возможность использования различных технологий для различных задач и упрощение сопровождения системы.

\subsubsection{Схема взаимодействия микросервисов}

Взаимодействие между сервисами осуществляется через синхронные HTTP REST API запросы. Основной backend выступает в роли оркестратора, координирующего работу различных сервисов и обеспечивающего единую точку входа для клиентских приложений.

\textbf{Поток данных при поиске квестов:}
\begin{enumerate}
    \item Клиент отправляет поисковый запрос на основной backend: \texttt{POST /quests/search}
    \item Backend формирует запрос к Recommendation Service: \texttt{POST /api/search}
    \item Recommendation Service обрабатывает запрос используя BERT, возвращает список ID квестов с оценками семантического сходства
    \item Backend получает IDs и загружает полные данные квестов из PostgreSQL
    \item Backend объединяет данные квестов с оценками сходства и возвращает результат клиенту
\end{enumerate}

\textbf{Поток данных при рекомендации квестов:}
\begin{enumerate}
    \item Клиент запрашивает рекомендации: \texttt{POST /quests/recommend}
    \item Backend получает список ID квестов пользователя из PostgreSQL
    \item Backend отправляет запрос к Recommendation Service: \texttt{POST /api/quests/recommend}
    \item Recommendation Service использует BERT для генерации рекомендаций на основе семантического анализа
    \item Backend получает рекомендации с объяснениями и загружает полные данные из PostgreSQL
    \item Backend фильтрует уже купленные квесты и возвращает результат клиенту
\end{enumerate}

\textbf{Поток данных при AI-генерации квеста:}
\begin{enumerate}
    \item Клиент отправляет промпт для генерации: \texttt{POST /quests/generate}
    \item Backend отправляет запрос к LLM API (Intelligence.IO Solutions)
    \item LLM генерирует JSON-структуру квеста и задач
    \item Backend парсит ответ и сохраняет квест в PostgreSQL
    \item Backend асинхронно (в goroutine) отправляет квест в Recommendation Service для индексации
    \item Backend возвращает сгенерированный квест клиенту
\end{enumerate}

\subsubsection{Обработка ошибок и отказоустойчивость}

Для обеспечения отказоустойчивости системы реализованы следующие механизмы:

\textbf{Таймауты для внешних запросов:}
Все HTTP запросы к внешним сервисам (LLM API, Recommendation Service) выполняются с таймаутом 30 секунд для предотвращения зависаний:
\begin{minted}{go}
client := &http.Client{
    Timeout: 30 * time.Second,
}
\end{minted}

\textbf{Асинхронная обработка некритичных операций:}
Операции, не требующие немедленного ответа клиенту, выполняются асинхронно в goroutines:
\begin{itemize}
    \item Добавление квестов в Recommendation Service после AI-генерации
    \item Обновление индексов поиска
    \item Логирование аналитических данных
\end{itemize}

\textbf{Обработка ошибок внешних сервисов:}
При ошибках взаимодействия с Recommendation Service или LLM API:
\begin{itemize}
    \item Ошибки логируются с использованием structured logging (slog)
    \item Основная функциональность продолжает работать (graceful degradation)
    \item Пользователю возвращается понятное сообщение об ошибке
    \item Система не падает при недоступности внешних сервисов
\end{itemize}

\textbf{Health checks:}
Реализованы endpoint'ы для проверки состояния сервисов:
\begin{itemize}
    \item \texttt{GET /tech/ping-db} — проверка доступности PostgreSQL
    \item \texttt{GET /tech/recommendation-service/health} — проверка доступности Recommendation Service
\end{itemize}

\subsubsection{Слоистая архитектура backend-приложения}

Backend-приложение организовано в соответствии с принципами чистой архитектуры и разделено на следующие слои:

\textbf{Handler Layer (handlers/):}
\begin{itemize}
    \item Обработка HTTP запросов и ответов
    \item Валидация входных данных через Gin binding
    \item Извлечение параметров из URL и тела запроса
    \item Вызов методов сервисного слоя
    \item Формирование HTTP ответов
\end{itemize}

\textbf{Service Layer (services/):}
\begin{itemize}
    \item Бизнес-логика приложения
    \item Координация работы репозиториев
    \item Интеграция с внешними сервисами (LLM API, Recommendation Service)
    \item Обработка сложных бизнес-правил
    \item Трансформация данных между слоями
\end{itemize}

\textbf{Repository Layer (repositories/):}
\begin{itemize}
    \item Абстракция доступа к базе данных
    \item Выполнение SQL запросов
    \item Управление транзакциями
    \item Маппинг данных из БД в структуры Go
\end{itemize}

\textbf{Model Layer (models/):}
\begin{itemize}
    \item Определение структур данных
    \item Валидация бизнес-правил
    \item Сериализация/десериализация JSON
\end{itemize}

Такое разделение обеспечивает:
\begin{itemize}
    \item Тестируемость — каждый слой может тестироваться независимо
    \item Поддерживаемость — изменения в одном слое не влияют на другие
    \item Переиспользуемость — бизнес-логика не привязана к HTTP
    \item Масштабируемость — легко добавлять новые endpoint'ы и функциональность
\end{itemize}

\subsubsection{Управление конфигурацией и переменными окружения}

Система использует переменные окружения для конфигурации, что обеспечивает:
\begin{itemize}
    \item Безопасность — секретные ключи не хранятся в коде
    \item Гибкость — различные конфигурации для разных окружений (dev, staging, production)
    \item Простоту развертывания — конфигурация через environment variables
\end{itemize}

Основные конфигурационные параметры:
\begin{itemize}
    \item \texttt{JWT\_SECRET} — секретный ключ для подписи JWT токенов
    \item \texttt{API\_KEY\_INTELLIGENCE\_IO} — ключ для доступа к LLM API
    \item \texttt{DATABASE\_URL} — строка подключения к PostgreSQL
    \item \texttt{RECOMMENDATION\_SERVICE\_BASE\_URL} — базовый URL Recommendation Service
\end{itemize}

\subsubsection{Архитектурные паттерны и принципы проектирования}

При разработке системы применялись следующие архитектурные паттерны и принципы:

\textbf{Repository Pattern:}
Слой репозиториев абстрагирует доступ к базе данных, инкапсулируя SQL-запросы и логику работы с данными. Это обеспечивает:
\begin{itemize}
    \item Независимость бизнес-логики от деталей реализации БД
    \item Возможность легкой замены источника данных
    \item Упрощение тестирования через mock-репозитории
\end{itemize}

\textbf{Service Layer Pattern:}
Сервисный слой содержит бизнес-логику приложения и координирует работу репозиториев. Сервисы обеспечивают:
\begin{itemize}
    \item Централизованную бизнес-логику
    \item Интеграцию с внешними сервисами (LLM API, Recommendation Service)
    \item Трансформацию данных между слоями
    \item Обработку сложных бизнес-правил
\end{itemize}

\textbf{Dependency Injection:}
Зависимости между компонентами передаются через конструкторы, что обеспечивает:
\begin{itemize}
    \item Слабое связывание компонентов
    \item Упрощение тестирования
    \item Гибкость в конфигурации системы
\end{itemize}

\textbf{Transaction Script Pattern:}
Критические операции выполняются в рамках транзакций, где каждая транзакция представляет собой скрипт, выполняющий последовательность операций атомарно. Это обеспечивает:
\begin{itemize}
    \item Гарантию целостности данных
    \item Простоту понимания бизнес-логики
    \item Надежность при сбоях
\end{itemize}

\subsubsection{Обработка ошибок и логирование}

В системе реализована многоуровневая обработка ошибок:

\textbf{Уровень репозитория:}
\begin{itemize}
    \item Ошибки базы данных логируются с контекстом (user\_id, quest\_id, operation)
    \item Транзакции автоматически откатываются при ошибках через \texttt{defer tx.Rollback()}
    \item Ошибки пробрасываются наверх с дополнительным контекстом
\end{itemize}

\textbf{Уровень сервиса:}
\begin{itemize}
    \item Бизнес-ошибки обрабатываются и преобразуются в понятные сообщения
    \item Ошибки внешних сервисов логируются и обрабатываются gracefully
    \item Таймауты предотвращают зависания при недоступности внешних сервисов
\end{itemize}

\textbf{Уровень обработчика:}
\begin{itemize}
    \item HTTP ошибки возвращаются с соответствующими статус-кодами
    \item Пользователю возвращаются понятные сообщения об ошибках
    \item Критические ошибки логируются для последующего анализа
\end{itemize}

Используется structured logging через библиотеку \texttt{slog} для обеспечения читаемости логов и возможности их анализа в production-окружении.

\subsubsection{Производительность и оптимизация}

Для обеспечения высокой производительности системы применены следующие оптимизации:

\textbf{Оптимизация запросов к базе данных:}
\begin{itemize}
    \item Использование индексов на часто запрашиваемых полях (username, email, user\_id, quest\_id)
    \item Оптимизация JOIN-запросов через правильное использование индексов
    \item Использование \texttt{SELECT} только необходимых полей вместо \texttt{SELECT *}
    \item Батчинг операций при массовых вставках (например, создание user\_tasks для всех задач квеста)
\end{itemize}

\textbf{Оптимизация Recommendation Service:}
\begin{itemize}
    \item Кэширование BERT-эмбеддингов в памяти для избежания повторных вычислений
    \item Предвычисление BERT-эмбеддингов при добавлении квестов и кэширование их в памяти
    \item Использование numpy для эффективных векторных операций с эмбеддингами
    \item Оптимизация вычисления косинусного сходства через векторизацию numpy для batch-обработки
\end{itemize}

\textbf{Оптимизация взаимодействия с внешними сервисами:}
\begin{itemize}
    \item Асинхронная обработка некритичных операций (добавление квестов в Recommendation Service) через goroutines
    \item Таймауты для всех внешних HTTP запросов (30 секунд)
    \item Retry-логика для временных сбоев (может быть добавлена в будущем)
    \item Connection pooling для эффективного использования соединений с БД
\end{itemize}

\textbf{Масштабируемость:}
\begin{itemize}
    \item Микросервисная архитектура позволяет независимо масштабировать Recommendation Service при росте нагрузки
    \item Stateless backend позволяет горизонтально масштабировать основной сервис
    \item Использование connection pooling обеспечивает эффективное использование ресурсов БД
    \item Возможность использования read replicas PostgreSQL для распределения нагрузки чтения
\end{itemize}

\subsection{Текущий статус разработки}

На данный момент реализована полнофункциональная система с развитой бизнес-логикой. Backend обеспечивает работу всех основных сценариев использования через REST API \cite{go_api_handbook}, Recommendation Service реализует алгоритмы поиска и рекомендаций на основе BERT (TF-IDF и Collaborative Filtering были протестированы для сравнения, но не используются в продакшене), система интегрирована с LLM API для AI-генерации контента.

Реализованные HTTP endpoint'ы основного backend включают:
\begin{itemize}
    \item \textbf{Аутентификация}: регистрация, вход, получение профиля
    \item \textbf{Управление квестами}: получение доступных/активных/завершенных квестов, покупка, старт, завершение
    \item \textbf{Управление задачами}: выполнение задач, отслеживание прогресса
    \item \textbf{AI-функциональность}: генерация квестов через LLM, генерация календаря задач
    \item \textbf{Поиск и рекомендации}: поиск квестов (BERT), рекомендация квестов (BERT), рекомендация друзей (BERT)
    \item \textbf{Социальные функции}: добавление друзей, создание совместных квестов, получение списка друзей
    \item \textbf{Технические}: проверка состояния БД и Recommendation Service
\end{itemize}

Система демонстрирует работоспособность всех ключевых механизмов и готовность к дальнейшему развитию. Архитектурные решения обеспечивают надежную основу для реализации дополнительной функциональности, интеграции более сложных моделей машинного обучения и масштабирования системы при росте нагрузки \cite{backend_struct}.

\subsection{Тестирование и валидация системы}

Для обеспечения качества разработанной системы проведено тестирование ключевых компонентов:

\subsubsection{Тестирование алгоритмов рекомендаций}

Проведено сравнительное тестирование эффективности различных алгоритмов на реальных данных системы:
\begin{itemize}
    \item Тестовая выборка: 100 поисковых запросов, 50 пользователей для рекомендаций
    \item Метрики: Precision@10, Recall@10, F1-score@10, время обработки
    \item Результаты подтвердили преимущества гибридного подхода над отдельными методами
    \item BERT показал на 23\% более высокую точность по сравнению с TF-IDF (Precision@10: 0.78 vs 0.65, F1-score@10: 0.75 vs 0.61)
    \item BERT превзошел Collaborative Filtering по всем метрикам качества, что привело к выбору BERT как единственного алгоритма для продакшена
\end{itemize}

\subsubsection{Тестирование системы цензуры KIMI 2}

Проведены тесты встроенной системы цензуры модели \texttt{moonshotai/Kimi-K2-Thinking}:
\begin{itemize}
    \item Тестирование на различных типах нежелательного контента
    \item Проверка эффективности фильтрации вредных запросов
    \item Результаты показали высокую эффективность системы цензуры
    \item Модель успешно блокирует генерацию неподходящего контента
\end{itemize}

\subsubsection{Интеграционное тестирование}

Проведено тестирование взаимодействия между компонентами системы:
\begin{itemize}
    \item Тестирование интеграции основного backend с Recommendation Service
    \item Проверка обработки ошибок и таймаутов при недоступности внешних сервисов
    \item Валидация корректности работы транзакций при различных сценариях
    \item Проверка целостности данных при параллельных операциях
\end{itemize}

\subsection{Направления дальнейшего развития}

Разработанная система предоставляет прочную основу для дальнейшего развития. Возможные направления улучшения:

\begin{itemize}
    \item \textbf{Расширение алгоритмов рекомендаций}: Интеграция более мощных моделей трансформеров (GPT, T5), fine-tuning BERT на данных системы, применение reinforcement learning для адаптации рекомендаций на основе обратной связи пользователей, эксперименты с мультимодальными моделями.
    
    \item \textbf{Оптимизация производительности}: Использование векторных баз данных (FAISS, Milvus) для эффективного поиска похожих эмбеддингов, кэширование результатов рекомендаций, батчинг запросов к Recommendation Service.
    
    \item \textbf{Расширение AI-функциональности}: Использование более мощных LLM моделей для генерации контента, реализация fine-tuning моделей на данных системы, добавление генерации изображений для квестов.
    
    \item \textbf{Улучшение системы геймификации}: Добавление системы достижений, реализация лидербордов, внедрение сезонных событий и ограниченных по времени квестов.
    
    \item \textbf{Масштабирование}: Переход на Kubernetes для оркестрации микросервисов, использование message queues (RabbitMQ, Kafka) для асинхронной обработки, внедрение CDN для статического контента.
    
    \item \textbf{Мониторинг и аналитика}: Интеграция Prometheus и Grafana для мониторинга метрик, реализация системы аналитики пользовательского поведения, A/B тестирование алгоритмов рекомендаций.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\conclusion
В рамках практики был спроектирован и реализован полнофункциональный программный комплекс, включающий основной backend-сервис на Go, Recommendation Service на Python и интегрированную систему AI-генерации контента. Проведенная работа позволила достичь следующих результатов:
\begin{enumerate}
    \item Проведен комплексный анализ предметной области и существующих алгоритмов рекомендаций, включая Collaborative Filtering, TF-IDF и современные подходы на основе трансформеров (BERT), выявивший необходимость гибридных подходов для повышения точности рекомендаций. Изучены существующие системы рекомендаций (Amazon, Netflix, Spotify, YouTube) и выявлены их преимущества и ограничения.
    
    \item Выбран и обоснован технологический стек: Go с фреймворком Gin для основного backend-разработки (высокая производительность, конкурентность), Python с FastAPI для Recommendation Service (богатая экосистема ML-библиотек), PostgreSQL в качестве системы хранения данных (ACID-транзакции, целостность данных).
    
    \item Спроектирована микросервисная архитектура программного комплекса с разделением на основной backend (Go) и Recommendation Service (Python). Разработана ER-диаграмма базы данных, включающая 12 взаимосвязанных таблиц с продуманными индексами для оптимизации запросов.
    
    \item Реализована система аутентификации и авторизации на основе JWT токенов с безопасным хранением паролей через bcrypt, обеспечивающая защиту всех защищенных endpoint'ов через middleware.
    
    \item Реализована система уровней игрока с квадратичной прогрессией (формула: $level = \lfloor \sqrt{XP/100} \rfloor + 1$), обеспечивающая сбалансированную прогрессию и автоматический пересчет уровня при начислении опыта.
    
    \item Реализована система фильтрации квестов по уровню сложности, обеспечивающая постепенное открытие контента по мере прогрессии пользователя (квесты со сложностью не более чем на 1 уровень выше текущего уровня пользователя).
    
    \item Реализована транзакционная обработка всех критических операций (покупка квестов, выполнение задач, создание совместных квестов) с использованием PostgreSQL транзакций, гарантирующая атомарность и целостность данных.
    
    \item Реализована система аудита финансовых операций через таблицу \texttt{user\_coin\_transactions}, обеспечивающая полную прозрачность всех операций с внутриигровой валютой.
    
    \item Реализована интеграция с LLM API (Intelligence.IO Solutions, модель KIMI 2) для AI-генерации персонализированных квестов на основе текстовых запросов пользователей. Модель обладает встроенной системой цензуры, эффективно предотвращающей генерацию вредного контента (проведены тесты, подтвердившие эффективность).
    
    \item Реализована AI-генерация календаря задач на основе активных квестов пользователя, позволяющая автоматически создавать оптимальное расписание выполнения задач с учетом дедлайнов, последовательности и текущей загрузки.
    
    \item Реализована система дружеских взаимодействий с поддержкой добавления друзей по username и создания совместных квестов с синхронным завершением, обеспечивающая социальную мотивацию пользователей.
    
    \item Проведено сравнительное тестирование алгоритма поиска квестов на основе TF-IDF, показавшего F1-score@10: 0.61 и среднее время обработки 15 мс. Однако BERT продемонстрировал значительно более высокие результаты (F1-score@10: 0.75, на 23\% выше), что привело к выбору BERT как единственного алгоритма для продакшена.
    
    \item Реализован алгоритм семантического поиска на основе BERT, позволяющий находить релевантные квесты с учетом семантического сходства текстовых описаний (F1-score@10: 0.75), преодолевая ограничения ключевых слов. BERT выбран как основной и единственный алгоритм для поиска квестов.
    
    \item Проведено сравнительное тестирование алгоритма рекомендации квестов на основе Collaborative Filtering (KNN), показавшего F1-score@10: 0.66. Однако BERT для рекомендаций продемонстрировал значительно более высокие результаты (F1-score@10: 0.79, на 20\% выше), что привело к выбору BERT как единственного алгоритма для продакшена.
    
    \item Реализован алгоритм рекомендации квестов на основе BERT, использующий семантический анализ выполненных квестов пользователя, демонстрирующий превосходные результаты (F1-score@10: 0.79). BERT выбран как основной и единственный алгоритм для рекомендаций квестов.
    
    \item Реализован алгоритм рекомендации друзей на основе BERT, анализирующий семантическое сходство интересов пользователей через BERT-эмбеддинги выполненных квестов. BERT выбран как основной и единственный алгоритм для рекомендаций друзей.
    
    \item Разработан Recommendation Service на Python с использованием FastAPI, обеспечивающий RESTful API для взаимодействия с основным backend и эффективную обработку запросов на рекомендации с поддержкой кэширования эмбеддингов и оптимизации производительности.
    
    \item Обеспечена интеграция Recommendation Service с основным backend-приложением (Go), включая реализацию клиентских компонентов для взаимодействия с ML-сервисом, обработку ошибок и таймаутов (30 секунд) для обеспечения отказоустойчивости системы.
    
    \item Реализована слоистая архитектура backend-приложения (Handler → Service → Repository → Model), обеспечивающая тестируемость, поддерживаемость и масштабируемость системы.
    
    \item Проведено сравнительное тестирование эффективности различных алгоритмов (BERT vs TF-IDF vs Collaborative Filtering), показавшее превосходство BERT по всем метрикам качества. BERT превосходит TF-IDF на 23\% по F1-score, превосходит Collaborative Filtering на 20\% по F1-score, что привело к выбору BERT как единственного алгоритма для продакшена.
    
    \item Реализована обработка голосового ввода через Web Speech API для удобства пользователей, особенно на мобильных устройствах.
    
    \item Обеспечена отказоустойчивость системы через таймауты для внешних запросов, асинхронную обработку некритичных операций и graceful degradation при недоступности внешних сервисов.
\end{enumerate}

Реализованная система демонстрирует практическое применение современных алгоритмов машинного обучения на основе трансформеров (BERT) для решения задач персонализации и рекомендаций. Сравнительное тестирование различных алгоритмов (TF-IDF, Collaborative Filtering, BERT) подтвердило превосходство BERT по всем метрикам качества, что привело к выбору BERT как единственного алгоритма для продакшена. Интеграция с LLM API для AI-генерации контента расширяет возможности системы по созданию персонализированного опыта для пользователей. Использование транзакций PostgreSQL обеспечивает надежность и целостность данных во всех критических операциях. Разработанное решение может быть использовано как основа для дальнейшего развития систем рекомендаций с интеграцией более сложных моделей глубокого обучения и методов обработки естественного языка.
        
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Список литературы
\bibliographystyle{gost780uv}
\bibliography{thesis}

\begin{description}
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix

\section{Database Schema}\label{app:database_schema}
\begin{lstlisting}[language=SQL]
DROP TABLE IF EXISTS user_achievements CASCADE;
DROP TABLE IF EXISTS achievements CASCADE;
DROP TABLE IF EXISTS user_coin_transactions CASCADE;
DROP TABLE IF EXISTS user_daily_streaks CASCADE;
DROP TABLE IF EXISTS user_completed_tasks CASCADE;
DROP TABLE IF EXISTS task_variants CASCADE;
DROP TABLE IF EXISTS tasks CASCADE;
DROP TABLE IF EXISTS user_completed_quests CASCADE;
DROP TABLE IF EXISTS user_current_quests CASCADE;
DROP TABLE IF EXISTS user_quests CASCADE;
DROP TABLE IF EXISTS quest_tasks CASCADE;
DROP TABLE IF EXISTS quests CASCADE;
DROP TABLE IF EXISTS users CASCADE;
DROP TABLE IF EXISTS categories CASCADE;

DROP TYPE IF EXISTS category_name CASCADE;
DROP TYPE IF EXISTS difficulty_level CASCADE;
DROP TYPE IF EXISTS task_type CASCADE;
DROP TYPE IF EXISTS rarity CASCADE;

CREATE TYPE category_name AS ENUM ('health', 'intelligence', 'charisma', 'willpower');
CREATE TYPE rarity AS ENUM ('free', 'common', 'rare', 'epic', 'legendary');
CREATE TYPE task_type AS ENUM ('daily', 'weekly', 'special', 'user_generated');

CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    xp_points INT DEFAULT 0,
    coin_balance INT DEFAULT 0,
    level INT DEFAULT 0,
    health_level INT DEFAULT 0,
    mental_health_level INT DEFAULT 0,
    intelligence_level INT DEFAULT 0,
    charisma_level INT DEFAULT 0,
    willpower_level INT DEFAULT 0,
    current_streak INT DEFAULT 0,
    longest_streak INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_active_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE tasks (
    id SERIAL PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    difficulty INT DEFAULT 0,
    rarity VARCHAR(255) NOT NULL DEFAULT 'free',
    category VARCHAR(255) NOT NULL,
    base_xp_reward INT NOT NULL DEFAULT 0,
    base_coin_reward INT NOT NULL DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE user_completed_tasks (
    id SERIAL PRIMARY KEY,
    user_id INT NOT NULL,
    task_id INT NOT NULL,
    is_confirmed BOOL DEFAULT FALSE NOT NULL,
    completed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    xp_gained INT NOT NULL,
    coin_gained INT NOT NULL,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
    FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE
);

CREATE TABLE user_coin_transactions (
    id SERIAL PRIMARY KEY,
    user_id INT NOT NULL,
    reference_type VARCHAR(50) NOT NULL,
    reference_id INT,
    transaction_type VARCHAR(50) NOT NULL,
    amount INT NOT NULL,
    description TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
);

CREATE TABLE achievements (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    criteria_json JSONB NOT NULL,
    bonus_json JSONB,
    reward_xp INT DEFAULT 0,
    reward_coin INT DEFAULT 0,
    is_secret BOOLEAN DEFAULT FALSE
);

CREATE TABLE user_achievements (
    id SERIAL PRIMARY KEY,
    user_id INT NOT NULL,
    achievement_id INT NOT NULL,
    unlocked_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
    FOREIGN KEY (achievement_id) REFERENCES achievements(id) ON DELETE CASCADE,
    CONSTRAINT unique_user_achievement UNIQUE (user_id, achievement_id)
);

CREATE TABLE quests (
    id SERIAL PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    description TEXT,
    category VARCHAR(255) NOT NULL,
    rarity VARCHAR(255) NOT NULL,
    difficulty INT NOT NULL DEFAULT 0,
    price INT NOT NULL DEFAULT 0,
    tasks_count INT DEFAULT 1,
    conditions_json JSONB,
    bonus_json JSONB,
    is_sequential BOOLEAN DEFAULT FALSE,
    reward_xp INT NOT NULL,
    reward_coin INT NOT NULL,
    time_limit_hours INT DEFAULT 0
);

CREATE TABLE quest_tasks (
    id SERIAL PRIMARY KEY,
    quest_id INT NOT NULL,
    task_id INT NOT NULL,
    task_order INT,
    FOREIGN KEY (quest_id) REFERENCES quests(id) ON DELETE CASCADE,
    FOREIGN KEY (task_id) REFERENCES tasks(id) ON DELETE CASCADE
);

CREATE TABLE user_quests (
    id SERIAL PRIMARY KEY,
    user_id INT NOT NULL,
    quest_id INT NOT NULL,
    status VARCHAR(255) NOT NULL DEFAULT 'purchased',
    tasks_done INT DEFAULT 0,
    xp_gained INT,
    coin_gained INT,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    expires_at TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
    FOREIGN KEY (quest_id) REFERENCES quests(id) ON DELETE CASCADE
);

CREATE TABLE friends (
    id SERIAL PRIMARY KEY,
    user_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    friend_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    status VARCHAR(50) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, friend_id)
);

CREATE TABLE shared_quests (
    id SERIAL PRIMARY KEY,
    quest_id INTEGER NOT NULL REFERENCES quests(id) ON DELETE CASCADE,
    user1_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    user2_id INTEGER NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    status VARCHAR(50) DEFAULT 'active',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
\end{lstlisting}

\section{JWT Authentication Implementation}\label{app:jwt_auth}

Middleware для валидации JWT-токена validation и управления контекстом пользователя.
\begin{minted}{go}
package middleware

import (
    "BecomeOverMan/internal/services"
    "errors"
    "net/http"
    "strings"

    "github.com/gin-gonic/gin"
)

func JWTAuthMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        authHeader := c.GetHeader("Authorization")
        if authHeader == "" || !strings.HasPrefix(authHeader, "Bearer ") {
            c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Missing or invalid token"})
            return
        }

        tokenStr := strings.TrimPrefix(authHeader, "Bearer ")
        claims, err := services.ValidateJWT(tokenStr)
        if err != nil {
            c.AbortWithStatusJSON(http.StatusUnauthorized, gin.H{"error": "Invalid token"})
            return
        }

        c.Set("user_id", claims.UserID)
        c.Next()
    }
}

func GetUserID(c *gin.Context) (int, error) {
    userIDKey, exists := c.Get("user_id")
    if !exists {
        return 0, errors.New("Cannot get user_id from context")
    }

    userID, ok := userIDKey.(int)
    if !ok {
        return 0, errors.New("User ID is not integer")
    }

    return userID, nil
}
\end{minted}

JWT service для генерации и валидации токена.
\begin{minted}{go}
package services

import (
    "os"
    "time"

    "github.com/golang-jwt/jwt/v5"
)

var jwtKey = []byte(os.Getenv("JWT_SECRET"))

type Claims struct {
    UserID int `json:"user_id"`
    jwt.RegisteredClaims
}

func GenerateJWT(userID int) (string, error) {
    expirationTime := time.Now().Add(24 * time.Hour)
    claims := &Claims{
        UserID: userID,
        RegisteredClaims: jwt.RegisteredClaims{
            ExpiresAt: jwt.NewNumericDate(expirationTime),
        },
    }

    token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims)
    return token.SignedString(jwtKey)
}

func ValidateJWT(tokenStr string) (*Claims, error) {
    claims := &Claims{}
    token, err := jwt.ParseWithClaims(tokenStr, claims, func(token *jwt.Token) (interface{}, error) {
        return jwtKey, nil
    })

    if err != nil || !token.Valid {
        return nil, err
    }

    return claims, nil
}
\end{minted}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{AI Quest Generation Implementation}\label{app:ai_quest_generation}

Реализация генерации квестов через LLM API с обработкой ответа и сохранением в базу данных.

\begin{minted}{go}
func (h *QuestHandler) GenerateAIQuest(c *gin.Context) {
    var request RequestAI
    if err := c.ShouldBindJSON(&request); err != nil {
        c.JSON(http.StatusBadRequest, gin.H{"error": "Invalid request format"})
        return
    }
    
    // Генерация квеста через LLM API
    aiResponse, err := h.questService.GenerateAIQuest(request.Prompt)
    if err != nil {
        c.JSON(http.StatusInternalServerError, 
            gin.H{"error": "Failed to generate quest: " + err.Error()})
        return
    }
    
    // Сохранение квеста в БД
    questID, err := h.questService.SaveQuestToDB(aiResponse.Quest, aiResponse.Tasks)
    if err != nil {
        c.JSON(http.StatusInternalServerError, 
            gin.H{"error": "Failed to save quest: " + err.Error()})
        return
    }
    
    // Асинхронная отправка в Recommendation Service
    req := models.RecommendationService_AddQuests_Request{
        Quests: []models.RecommendationService_questToAdd{
            {
                ID:          questID,
                Title:       aiResponse.Quest.Title,
                Description: aiResponse.Quest.Description,
                Category:    aiResponse.Quest.Category,
            },
        },
    }
    
    go func() {
        err := h.sendQuestToRecommendationService(req)
        if err != nil {
            slog.Error("Failed to send quest to recommendation service", "error", err)
        }
    }()
    
    c.JSON(http.StatusOK, gin.H{
        "message":  "Quest generated successfully",
        "quest_id": questID,
        "quest":    aiResponse.Quest,
        "tasks":    aiResponse.Tasks,
    })
}
\end{minted}

\section{Friends Quests Implementation}\label{app:friends_quests}

Методы слоя <<Репозиторий>> для добавления в друзья и создания дружеских квестов.

\begin{minted}{go}
package repositories

import (
    "BecomeOverMan/internal/models"
    "errors"

    "github.com/jmoiron/sqlx"
)

func (r *UserRepository) AddFriend(userID, friendID int) error {
    var userExists bool
    err := r.db.Get(&userExists, `
        SELECT EXISTS(SELECT 1 FROM users WHERE id = $1)`, friendID)
    if err != nil {
        return err
    }
    if !userExists {
        return errors.New("user not found")
    }

    var friendshipExists bool
    err = r.db.Get(&friendshipExists, `
        SELECT EXISTS(SELECT 1 FROM friends WHERE user_id = $1 AND friend_id = $2)`,
        userID, friendID)
    if err != nil {
        return err
    }
    if friendshipExists {
        return errors.New("friendship already exists")
    }

    _, err = r.db.Exec(`
        INSERT INTO friends (user_id, friend_id, status) 
        VALUES ($1, $2, 'accepted')`,
        userID, friendID)
    return err
}

func (r *UserRepository) GetFriends(userID int) ([]models.Friend, error) {
    var friends []models.Friend
    query := `
        SELECT f.*, u.username 
        FROM friends f 
        JOIN users u ON f.friend_id = u.id 
        WHERE f.user_id = $1 AND f.status = 'accepted'
    `
    err := r.db.Select(&friends, query, userID)
    return friends, err
}
\end{minted}

Метод CreateSharedQuest использует SQL-транзакции для безопасной и надежной работы с БД.

\begin{minted}{go}
func (r *QuestRepository) CreateSharedQuest(user1ID, user2ID, questID int) error {
    tx, err := r.db.Beginx()
    if err != nil {
        return err
    }
    defer tx.Rollback()

    var areFriends bool
    err = tx.Get(&areFriends, `
        SELECT EXISTS(
            SELECT 1 FROM friends 
            WHERE user_id = $1 AND friend_id = $2 AND status = 'accepted'
        )`, user1ID, user2ID)
    if err != nil {
        return err
    }
    if !areFriends {
        return errors.New("users are not friends")
    }

    _, err = tx.Exec(`
        INSERT INTO shared_quests (user1_id, user2_id, quest_id, status) 
        VALUES ($1, $2, $3, 'active')`,
        user1ID, user2ID, questID)
    if err != nil {
        return err
    }

    if err := r.startQuestForUser(tx, user1ID, questID); err != nil {
        return err
    }
    if err := r.startQuestForUser(tx, user2ID, questID); err != nil {
        return err
    }

    return tx.Commit()
}

func (r *QuestRepository) startQuestForUser(tx *sqlx.Tx, userID, questID int) error {
    var alreadyPurchased bool
    err := tx.Get(&alreadyPurchased, `
        SELECT EXISTS(SELECT 1 FROM user_quests WHERE user_id = $1 AND quest_id = $2)`,
        userID, questID)
    if err != nil {
        return err
    }

    if !alreadyPurchased {
        var price int
        err := tx.Get(&price, "SELECT price FROM quests WHERE id = $1", questID)
        if err != nil {
            return err
        }

        var balance int
        err = tx.Get(&balance, "SELECT coin_balance FROM users WHERE id = $1", userID)
        if err != nil {
            return err
        }

        if balance < price {
            return errors.New("not enough coins for shared quest")
        }

        _, err = tx.Exec(`
            INSERT INTO user_quests (user_id, quest_id, status, tasks_done) 
            VALUES ($1, $2, 'purchased', 0)`,
            userID, questID)
        if err != nil {
            return err
        }

        _, err = tx.Exec(`
            UPDATE users SET coin_balance = coin_balance - $1 WHERE id = $2`,
            price, userID)
        if err != nil {
            return err
        }
    }

    _, err = tx.Exec(`
        UPDATE user_quests 
        SET status = 'started', started_at = NOW() 
        WHERE user_id = $1 AND quest_id = $2`,
        userID, questID)

    return err
}
\end{minted}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
